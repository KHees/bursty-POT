---
title: Peaks Over Threshold for Bursty Time Series
# titlerunning: Inference for Heavy-Tailed CTRMs
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
authors: 
- name: "Katharina Hees"
  address: University of Dortmund
  email: hees@statistik.uni-dortmund.de
  
- name: "Smarak Nayak"
  address: National Australia Bank
  email: smarak.nayak@nab.com.au
  
- name: "Peter Straka*"
  address: UNSW Sydney
  email: p.straka@unsw.edu.au 
  
authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed 
  distribution. The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  This article generalizes the Peaks Over Threshold (POT) model to the setting 
  where inter-event times are heavy-tailed and i.i.d.. For high thresholds and 
  infinite-mean waiting times, we show that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process.
  We model threshold crossing times and threshold exceedances jointly, and
  provide graphical means of estimating model parameters and assessing 
  model fit. Finally, we study two real-world, bursty time series, and 
  show how to extract parameter estimates as well as estimates for the time 
  of the next threshold crossing. 

bibliography: CTRMstats.bib

output: 
  rticles::springer_article: 
    fig_caption: yes

params:
  tail: 0.8
  n: 10000

preamble: |
  \usepackage{amssymb}
---

```{r get-rticles, eval=FALSE, include=FALSE}
# use this rticles version: 
devtools::install_github("strakaps/rticles", 
                         ref = "724aeb88d005e2f7befc37328633e7cb2bc1cce0")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRM)
library(MittagLeffleR)
library(magrittr)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour have received 
strong interest in the recent statistical physics literature 
[@Barabasi2005; @Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; 
@Min2010; @Karsai2011; @Bagrow2013]. They have been observed in the context 
of earthquakes, sunspots, neuronal activity and human communication [see 
@Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point processes [@hawkes1971point]), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
Extreme value theory provides models for the distribution of the events
with the largest magnitude. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@beirlantBook]. 
Then as one increases the threshold and thus decreases the threshold 
crossing probability $p$, the Poisson process is rarefied, i.e. its 
intensity decreases _linearly_ with $p$. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size increases and the threshold crossing
probability $p$ decreases, the fractional Poisson process is rarefied: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @Hees16; @Hees17], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Sections 3 &
4. 
A statistical procedure to estimate model parameters via stability plots 
is outlined in Section 5, and diagnostic plots for model criticism are 
discussed in Section 6. 
In Section 7, we give case studies for simulated data as well as for a
real-world dataset, with a discussion in Section 8. 
All statistical computations have been done in R, and all code, data, as 
well as the source code for this manuscript has been organized into an R 
software package, available at <https://github.com/strakaps/CTRM>. 


# Marked Renewal Process (MRP)

**Definition:** 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the *waiting times* or 
inter-arrival times and $J_k \in [x_L, x_R]$ as the *event magnitudes* 
or marks
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
If $W$ and $J$ are independent, the MRP is said to be *uncoupled*. 


In this setup, the $k$ magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on this simple model, we derive the following two random variables:

**Definition (MRP):** 

: Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
The random variables
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k$$
are called the *exceedance* resp. *time until exceedance* of level $\ell$.


By restarting the MRP at $\tau(\ell)$, one can inductively construct the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$.
Moreover, since we assume the uncoupled case, the two sequences are independent.[^1]

[^1]: To see why, note that $X(\ell)$ is, in distribution, simply equal to 
  $J | J > \ell$, independent of any waiting time $W_k$.

```{r thresholdedBursty, message=FALSE, fig.height=7, fig.cap="\\label{fig:thresholdedBursty}Exceedances (red) and Times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line)."}
#rpareto <- function(n,tail){
#          if(tail<=0) stop("tail must be positive")
#          rp <- (runif(n)/gamma(1-tail))^(-1/tail)
#          rp}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
#times<-cumsum(rpareto(n,tail))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctrm <- ctrm(data.frame(times, magnitudes)) 
par(mfrow = c(2,1))
plot(sim_ctrm, p = 0.01, main = "Simulated MRP") 
flares %>% ctrm() %>% plot(p = 0.02, log = 'y', main = "HXRBS data") 
```

Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top 
panel, where $W$ has a stable distribution with tail parameter 
$\beta =$ `r params$tail` (and skewness $1$ and location $0$), and 
where $J$ is from a standard Gumbel distribution. In the bottom panel, 
we plot a time series of solar flare intensities derived from a NASA
dataset [@HXRBS][^*]. Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear 
continuously. The threshold exceedances, however, appear to have the same 
statistical behaviour in both models. Observations below a threshold are 
commonly discarded in Extreme Value Theory; likewise, our MRP model
interprets these observations as noise and filters them out.

[^*]: The "complete Hard X Ray Burst Spectrometer event list" 
is a comprehensive reference for all measurements of the Hard X 
Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of 
launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 
events were detected, with the "vast 
majority being solar flares". The list includes the start time, peak time, 
duration, and peak rate of each event. We have used "start time" as the 
variable for event times, and "peak rate" as the variable for event 
magnitudes. 



# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state the key theorem below (a proof is in the appendix). 
For more details on regular variation and stable limit theorems, we 
recommend the book by @MeerschaertSikorskii. 

**Theorem:**  

: Let the waiting times $J_k$ be in the domain of attraction of a 
positively skewed sum-stable law with stability parameter $0 < \beta < 1$; 
more precisely,
$$
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
$$
for a function $b(n)$ which is regularly varying at $\infty$ with 
parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$. 
Write $p := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p)} \to W_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$
holds, where the Mittag-Leffler random variable $W_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sW_\beta)] = \frac{1}{1+s^\beta}.
$$


\noindent In general, for $\sigma > 0$ we write ${\rm ML}(\beta, \sigma)$ for the 
distribution of $\sigma W_\beta$. 
The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, from the point of view of applied statistics. 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11.

#### _Proof of Theorem:_
We interpret the threshold crossing time $T(\ell)$ as the hitting time of the 
underlying CTRM (Continuous Time Random Maxima) or "max-renewal process", 
and then utilize a result by @MeerschaertStoev08. 
The running maximum process is defined as 
$$
M(c) := J_1 \vee \ldots \vee J_{\lfloor c \rfloor},
$$
and since we assume that the $J_k$ have a continuous distribution, there exist 
norming functions $a(c)$ and $d(c)$ such that 
$$
\mathbf P\left[ \frac{M(c) - d(c)}{a(c)} \le \ell^* \right] 
\longrightarrow F(\ell^*), \quad t \to \infty
$$
where $F$ is a generalized extreme value distribution, and $\ell^*$ is any 
value from the support of $F$. 
The CTRM process is then defined via 
$$
V(t) = M(N(t)), \quad t \ge 0
$$
where $N(t)$ is the renewal process associated with the waiting times 
$W_k$: 
$$
N(t) = \max\{n: W_1 + \ldots + W_n \le t\}.
$$
Now a key observation is that
$$
T(\ell) = \inf\{t: V(t) > \ell\}, 
$$
and that 
$$
T(\ell) > t \quad \text{ if and only if } \quad V(t) \le \ell.
$$
By [Theorem 3.1, @MeerschaertStoev08], we have the stochastic process 
convergence 
$$
\frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\stackrel{d}{\longrightarrow} Y(t), \quad t > 0.
$$
where $Y(t)$ is a time-changed ("subordinated") extremal process, and where 
$\tilde b(c)$ is a regularly varying norming function which is
_inverse_ to $b(c)$, in the sense that 
$b(\tilde b(c)) \sim c \sim \tilde b(b(c))$. 

Without loss of generality, we choose $\ell^*$ such that $F(\ell^*) = 1/e$, 
and let $\ell = a(\tilde b(c)) \ell^* + d(\tilde b(c))$. 
We may then calculate 
$$
\mathbf P\left[ \frac{T(\ell)}{b(1/p)} > t \right]
= \mathbf P[T(\ell) > b(1/p) t]
= \mathbf P[V(ct) \le \ell]
= \ldots
$$
where we have substituted $c = b(1/p)$, 
$$
\ldots
= \mathbf P\left[ \frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\le \frac{\ell - d(\tilde b(c))}{a(\tilde b(c))} \right]
\longrightarrow \mathbf P\left[ Y(t) \le \ell^* \right]
= \ldots
$$
Defining the hitting time of level $\ell^*$ by $Y(t)$ as 
$\xi_{\ell^*} := \inf\{t: Y(t) > \ell^*\}$,
we then have 
$$
\ldots = \mathbf P[\xi_{\ell^*} > t] 
= \mathbf P[(-\log F(\ell^*))^{-1/\beta} X^{1/\beta} D > t]
$$
by [Proposition 4.2, @MeerschaertStoev08], where $X$ is an exponential 
random variable with mean $1$. 
Using [Theorem 19.1, @Haubold11], we see that 
$X^{1/\beta} D \sim {\rm ML}(\beta, 1)$, concluding the proof. 
\qed

# Inference for the Mittag-Leffler distribution

```{r fig:QQ-est, fig.cap="QQ-estimator plots for various datasets.\\label{fig:QQ-est}", fig.height=7, fig.width=7}
par(mfrow = c(2,2))
flares_exponent <- flares %>% ctrm() %>% thin(k=500) %>% qqestplot(static=TRUE, main = "QQ-static, flare magnitudes")
ML_exponent <- MittagLeffleR::rml(500, 0.8) %>% qqestplot(static=TRUE, main = "QQ-static, Mittag-Leffler data")
ML_exponent2 <- MittagLeffleR::rml(500, 0.8) %>% qqestplot(static=FALSE, top_k = 15, conf.int = TRUE, main = "lala")
exp_exponent <- rexp(500) %>% qqestplot(static=TRUE, main = "QQ-static, Exponential data")
```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers 
would intuitively give the highest importance to the tail behaviour of the 
distribution, and 
estimate the exponent of the tail function with established methods such 
as the Hill estimator. The QQ-estimator [@Kratz96] is closely related to 
the Hill estimator and fits a 
least squares line through the logarithms of the ordered statistics 
(y-axis) and the corresponding quantiles of the exponential distribution 
(x-axis), and returns the reciprocal slope as the estimate of the tail 
exponent.
For instance, the left panel in Figure \ref{fig:QQ-plots} shows the 
(static) QQ-estimator for the magnitudes of the solar flare data, returning 
a good fit to a Pareto distribution with tail parameter 
`r round(flares_exponent, 2)`.

However, as described nicely by @Resnick97, the less 
similar a heavy-tailed distribution is to a Pareto distribution, the less
useful a Hill estimator is. 
The top-right panel of \ref{fig:QQ-plots}, for instance, shows the 
QQ-estimator plot for $2000$ draws from the Mittag-Leffler distribution with 
tail parameter $0.8$. The stretched exponential shape means 
that the Mittag-Leffler distribution has more probability near $0$ than 
the Pareto distribution, severely biasing the estimator downwards 
(`r round(ML_exponent, 2)`). Hence a cutoff needs to be introduced, 
above which the tail exponent is fitted: The dynamic QQ-estimator 
plots the static QQ-estimates (y-axis) for different cutoffs (x-axis)
(see bottom-left panel). There is no apparent interval of stability, 
which could be taken to indicate a reasonable estimate for the true 
tail exponent $0.8$. 
Even worse, from a QQ-estimator point of view, there is no striking 
difference between the infinite mean ${\rm ML}(0.8,1)$ distribution and 
the light-tailed ${\rm Exp}(1)$ distribution (see bottom-right panel). 
In particular, if only few 
(e.g. $<100$) data are available, then the static QQ-estimator plots look 
virtually interchangeable. 

Hence if there is some prior expectation that the data are drawn from the 
Mittag-Leffler distribution
(as is the the case for threshold exceedance times),
then we recommend avoiding QQ-estimators and Hill plots altogether, 
and instead examining QQ-plots directly 
(see Figure \ref{fig:QQ-plots}). 
The scale parameter $\sigma$ is irrelevant for a QQ-Plot. 
The tail parameter $\beta$ can be estimated quickly via the log-moment 
method by @Cahoy2013, or via maximum likelihood. 
Both estimators are implemented in the R package `MittagLeffleR` 
[@MittagLeffleR]. 


```{r QQ-plots, fig.cap="QQ Plots for Mittag-Leffler data (left; $\\beta = 0.8$) and threshold crossing times / magnitudes for the solar flare data (middle / right; threshold is set at the 500th order statistic, $\\beta = 0.83$). Threshold crossing times appear to fit the Mittag-Leffler distribution well, whereas the Magnitudes appear to fit a Pareto distribution better (\\ref{fig:QQ-est}). "}
par(mfrow = c(1, 3))
rml(n = 500, tail = 0.8) %>% mlqqplot(tail = 0.8, log = 'xy', main = "Mittag-Leffler data")
flares_arrivals <- flares %>% ctrm() %>% thin(k = 500) %>% interarrival()
flares_arrivals_MLparam <- (flares_arrivals %>% mlmle())$par
mlqqplot(flares_arrivals, 
         tail = flares_arrivals_MLparam["tail"], 
         scale = flares_arrivals_MLparam["scale"],
         log = 'xy', 
         main = "Threshold crossing times")
flares %>% ctrm() %>% thin(k = 500) %>% coredata() %>% 
  mlqqplot(tail = 0.8, log = 'xy', main = "Magnitudes")
```


# Inference on Exceedance times

The Theorem in the [previous Section](#sec:scaling) implies that for high 
$\ell$ we may 
approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution.
Building on the POT (Peaks Over Threshold) method, we propose the 
following estimation procedure for the distribution of $T(\ell)$: 

1. For varying thresholds $\ell \uparrow x_R$, extract datasets of
  exceedance times $\{T(\ell, i)\}_i$.
  

2. Fit a Mittag-Leffler distribution to each dataset, which
  results in the $\ell$-dependent estimates $\{\hat\beta(\ell)\}_\ell$ and 
  $\{\hat \sigma(\ell)\}_\ell$.
  

3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. 
  Use $\hat \beta$ as an estimate for the tail parameter $\beta$ of the
  Mittag-Leffler distribution of exceedance times. 
  

4. Approximate $p \approx |\{k: J_k > \ell\}| / n$. 
  Recall that $b(c)$ is regularly varying with parameter $1/\beta$, and 
  hence has the representation $b(c) = L(c) c^{1/\beta}$ for some 
  slowly varying function $L(c)$. 
  Assuming that the variation of $L(c)$ is negligible, we hence 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ is expected to stabilize around a constant 
  $\hat \sigma_0$. 
  We then use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 

The above approach, though theoretically sound, benefits from the following
practical adjustments:

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 
* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by the multiplicative constant $n^{1/\hat \beta}$, 
  but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0).
\end{align*}
For quick estimates of the Mittag-Leffler parameters the method of
log-transformed moments by @Cahoy2013 was used.


# Checking Model Assumptions 

The CTRM model is based on three main assumptions, which are repeated 
below. For each assumption, we suggest one means of checking if it holds: 

I.i.d.:
: The pairs $(W_i, J_i)$ are i.i.d. An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  
  

Uncoupled:
: Each $W_i$ is independent of each $J_i$. We propose an empirical copula
  plot to check for any dependence. 
  
  

Heavy tails:
: The waiting times are heavy-tailed with tail parameter 
  $\beta \in (0,1)$. A Hill plot can confirm this assumption. 


The motivation behind a CTRM model is to fit extreme observations
and their inter-arrival times. 
Observations below a certain threshold may be interpreted as noise and 
discarded.
Since the signal rather than the noise needs to satisfy our modelling 
assumptions, we suggest that the above model assumptions are checked 
*after* the noisy small observations are discarded. 


# Application to data

## Simulated Data

To test our inference method, we have simulated `r params$n` 
independent
waiting time and magnitude pairs $(W_k, J_k)$. In order to have exact 
analytical values available for $\beta$ and $\sigma_0$, a distribution for 
$W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:Wscale} is known. 
If we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{theD}, 
then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation (see e.g. the vignette on parametrisation in @MittagLeffleR) 
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. 

```{r make-caption}
caption = "Tail and scale estimates for simulated data, with waiting times drawn from the stable distribution $S_\\beta(\\cos(\\pi \\beta/2)^{1/\\beta}, +1, 0)$ with $\\beta = 0.8$. Dashed lines are 95\\% confidence intervals, dotted lines are the known theoretical values ($0.8$ and $10000^{1/0.8}$). \\label{fig:sim}"
```


```{r simulated-example, message=FALSE, fig.cap=caption}
k_max <- 500 
thin_sim_ctrm <- thin(ctrm = sim_ctrm, k = k_max)
par(mfrow=c(1,2))
MLestimates(ctrm = thin_sim_ctrm, tail = tail, scale = n^(1/tail))
```

By \eqref{eq:Tellscale}, the distribution 
of $T(\ell)$ is approximately 
${\rm ML}(\beta, p^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta})$, which means 
$\sigma_0 = n^{1/\beta}$.
The distribution of $J_k$ is irrelevant for the inference on $\beta$ and 
$\sigma_0$ (we have chosen unit exponential random variables). 
Figure \ref{fig:sim} displays plots of $\hat \beta(\ell)$ and 
$\hat \sigma(\ell)$ vs. $k$, the number of exceedances as $\ell$ traverses 
the largest observations $J_i$. 
Dotted lines show 95% confidence intervals, which are derived from the 
asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR].
The dashed lines show the actual values of $\beta$ resp.\ $\sigma_0$, 
showing that our inference method effectively identifies the 
right parameters. 


## Bitcoin trading volumes

```{r bitcoin-data, fig.cap="\\label{fig:bitcoin-data}Time Series of 'Bitcoin days destroyed', a measure for the traded volume of bitcoins."}
bitcoin_ctrm <- ctrm(bitcoin)
plot(bitcoin_ctrm, p = 0.02)
```


We study the daily trade volumes of Bitcoin since 2009, provided by 
Blockchain and downloaded from Data 
Market\footnote{\url{https://datamarket.com/data/list/?q=provider:blockchain}}. 
Although the observations are regular (daily), extremes in the trade volumes
occur in bursts, which can be seen over timescales of months and years 
(Figure \ref{fig:bitcoin-data}). 

```{r bitcoin-data-tail-scale, message=FALSE, fig.cap="\\label{fig:bitcoin-tail-scale}Tail and scale plot of the bitcoin data."}
thin_bitcoin_ctrm <- thin(ctrm = bitcoin_ctrm, k = 250)
par(mfrow=c(1,2))
MLestimates(thin_bitcoin_ctrm, tail = 0.9, scale = 2 * 1E3)
```

Figure \ref{fig:bitcoin-tail-scale} shows plots identifying the candidates
$\beta = 0.9$ and $\sigma_0 = 2000$ for 
the tail and scale parameters of the exceedance time distribution. 
That is, exceedances of a threshold $\ell$ at the $k$-th largest observed 
magnitude are distributed as 
$$T(\ell) = \text{ML}(0.9, 2000 * k^{-1/0.9}).$$ 
A QQ plot (Figure \ref{fig:bitcoin-diag}) of the exceedance times at the 
level of the 200th 
largest event lends credence to a heavy-tailed distribution with tail
parameter near the value $1$. 


## Solar Flare Data

```{r solar-flare-data, fig.cap="\\label{fig:solar-flare-data}The solar flare time series data."}
flares_ctrm <- ctrm(flares)
plot(flares_ctrm, p = 0.01)
```



The "complete Hard X Ray Burst Spectrometer event list" 
\footnote{\url{https://umbra.nascom.nasa.gov/smm/hxrbs.html}} 
@HXRBS is a 
comprehensive reference for all measurements of the Hard X 
Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of 
launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 
events were detected, with the "vast 
majority being solar flares". The list includes the start time, peak time, 
duration, and peak rate of each event. We have used "start time" as the 
variable for event times, and "peak rate" as the variable for event 
magnitudes (Figure \ref{fig:solar-flare-data}). 

```{r solar-flare-tail-scale, message=FALSE, fig.cap="\\label{fig:flares}Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset."}
thin_flares_ctrm <- thin(ctrm = flares_ctrm, k = 150)
par(mfrow=c(1,2))
MLestimates(thin_flares_ctrm, tail = tail, scale = 2.5 * 1E7)
```

Figure \ref{fig:flares} shows the fitted tail and scale parameters 
of the Mittag-Leffler distribution. The dotted line for the tail 
parameter is at $\beta = 0.85$, yielding the plot of (transformed) scale 
estimates $\hat \sigma_0 = k^{1/0.85} \hat \sigma(\ell)$. 
We suggest the estimate $\sigma_0 = 2.5 \times 10^7$ seconds 
$\approx 289$ days. 
The exceedance times of a threshold $\ell$ as high as the $k$-measurement 
are hence Mittag-Leffler distributed as
$$ T(\ell) \sim {\rm ML}(0.85, 289  k^{-1/0.85} \text{ days}).$$


# Discussion

Comparing plots of the simulated data in Figure \ref{fig:thresholdedBursty}
with plots of the 
empirical data \ref{fig:bitcoin-data} and \ref{fig:solar-flare-data}, 
it can be seen that the empirical data show long time intervals without 
*any* event occurring, whereas for real-world data events appear to happen 
continuously. 
This seeming discrepancy vanishes, however, when all but the $k_\text{max}$
largest observations are discarded. 
We repeat that the CTRM model focuses on extreme events and interprets 
smaller events as noise. 

The CTRM model, moreover, assumes a "pure" power-law for the event 
inter-arrival times. 
Real datasets, however, are often exponentially 
tapered or truncated, see e.g. the discussion of tempered power-law 
distributions by @MeerschaertRoyQin and the truncated Pareto distribution 
by @Aban06. 
This means that the fit to a power-law
distribution may seem adequate for medium-size time scales, 
but that at very large time-scales the power-law character of the 
distribution can weaken or disappear.
This behaviour seems to appear in both the Bitcoin data and the Solar-Flare
data: the Hill plot for the tail parameter is increasing towards lighter
tails as the threshold reaches very high values. 
This may mean that the CTRM model may overestimate the heaviness of the
tail of the waiting time distribution; or that a CTRM base on a *tempered* 
power-law renewal process might be a more realistic model. 

# Conclusion

We have proposed the CTRM model for the extremes of "bursty" events. 
Burstiness is a phenomenon of intermittency which has received a lot of 
attention in the recent statistical physics literature. 
The CTRM model is a straightforward generalization of the POT (Peaks over 
Threshold) model, for which the inter-arrival times between threshold 
crossings are exponentially distributed. 
If the Mittag-Leffler tail parameter of the CTRM equals $1$, then the 
CTRM model reproduces this behaviour exactly, showing that the CTRM model 
nests the POT model. 

The scale parameter $\sigma$ of the inter-event distribution follows a 
power-law $\sigma \propto p^{-1/\beta}$, where $\beta \in (0,1)$ is the 
tail parameter of the inter-event distribution and $p$ the probability 
that an event crosses a given threshold. 
From this power law, we have constructed "stability plots", from which 
estimates of $\beta$ and $\sigma$ can be read off. 

We have demonstrated the applicability of the CTRM model with two 
real-world datasets. 
Although the CTRM model possibly overestimates the heaviness of the tail 
of the inter-arrival distribution, it clearly captures that 
the inter-arrival times of threshold crossings scale non-linearly with 
the treshold crossing probability, and follow a clearly non-Poissonian 
behaviour. 
Thus we have shown that the CTRM model is a useful tool for the modelling 
of extremes of bursty events, which requires very little computation and 
which allows for straightforward ways of checking and criticizing model 
assumptions. 
The analyses from this paper are readily reproduced via the R package 
`CTRM`, available at \url{https://github.com/strakaps/CTRM}. 

## Acknowledgements

The authors would like to thank Peter Scheffler for insights on 
stochastic process limits for CTRMs, and Gurtek Gill who helped create
the MittagLeffleR R-package. 

\appendix


For our inference on the CTRM model, we extract realizations of 
$X(\ell)$ and $T(\ell)$ from time series data by considering thresholds 
$\ell$ ranging over some interval $[\ell_0, x_R)$. 
(A reasonable default value for $\ell_0$ is the $95$-th
percentile of $J$.)
Write $X(\ell,i)$ for the $i$-th exceedance of level $\ell$, 
and $T(\ell,i)$ for the inter-arrival time between
$X(\ell,i-1)$ and $X(\ell,i)$. 
Thus for any threshold $\ell \in [\ell_0, x_R)$,
we construct sequences $\{T(\ell,i)\}_{i}$ and 
$\{X(\ell,i)\}_{i}$. 
These sequences are i.i.d. because a renewal occurs at each threshold
crossing time, and independent because $W_k$ and $J_k$ are uncoupled.
Extracting the exceedances $X(\ell)$ for inference is a standard procedure
known as the Peaks Over Threshold (POT) approach in extreme value theory
[@beirlantBook].
Figure \ref{fig:thresholdedBursty} illustrates the exceedances 
$X(\ell, i)$ in red and the times until exceedance $T(\ell, i)$ as the 
preceding intervals marked by blue crosses. 


A standard result from extreme value theory provides the asymptotic 
distribution of $X(\ell)$ as $\ell \uparrow x_R$. For later use, we also 
include the scaling limit of the cumulative maximum $M(n)$. 

**Theorem GEV** (e.g. Chapter 2 & Section 5.3, @beirlantBook):

: Suppose the distribution of $J_k$ is continuous. Then there
exist non-decreasing norming functions $a(c)$ and $d(c)$ such that
as $c \to \infty$, the running maximum\footnote{We extend $M(n)$ 
continuously to $[0, +\infty)$ via $M(c) := M(\lfloor c \rfloor)$ where 
$\lfloor c \rfloor$ is the 
greatest integer not greater than $c$.} 
$M(c)$ converges weakly 
to a *Generalized Extreme Value Distribution* with shape
parameter
$\xi$:
\begin{align}
[M(c) - d(c)] / a(c) \stackrel{d}{\to} A, 
\quad
\mathbf P(A \le z) = G(z | \xi) = \exp\left(-[1+\xi z]^{-1/\xi}\right),\label{eq:GEV}
\end{align}
defined for all $z$ such that $1 + \xi z > 0$. 
This definition extends continuously to $\xi = 0$ via 
$$G(z | 0) = \exp(-\exp(-x)).$$
For $\mu$ and $\sigma > 0$, we write ${\rm GEV}(\xi, \mu, \sigma)$ for the 
probability distribution of the random variable $\sigma A + \mu$. 

    Moreover, asymptotically as $\ell \uparrow x_R$,
$$\mathbf P(J - \ell > y | J > \ell) 
\sim 1 - H(y),$$
where 
$$H(y) = \begin{cases}
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0,\infty) \text{ if } \xi > 0,\\
1 - \exp(-y/\tilde \sigma), & y \in (0,\infty) \text{ if } \xi = 0,\\
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0, -\sigma / \xi) \text{ if } \xi < 0
\end{cases}$$

    and where $\tilde \sigma := \sigma + \xi(\ell-\mu)$.
The CDF $H(y)$ is said to belong to the *Generalised Pareto family*
$GP(\xi,\bar \sigma)$.


# CTRM Scaling limits

## Waiting times

We will assume that the waiting times $W_k$ have infinite mean,
i.e. a tail parameter $\beta \in (0,1)$ and regularly varying tail probabilities:
$\mathbf P(W > t) \sim L(t) t^{-\beta}$ as $t \uparrow \infty$ for
some slowly varying function $L(t)$. As usually, $f(t) \sim g(t)$
means that the quotient of $f(t)$ and $g(t)$ converges to $1$. The
law of the $W$ then lies in the domain of attraction of a stable law,
in the sense that the distributional limit 
\begin{align} \label{eq:Wscale}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
exists, for a regularly varying scaling function
\begin{equation} \label{eq:bScale}
b \in {\rm RV}_\infty(1/\beta)
\end{equation}
[See e.g. Section 2.9.2 in @beirlantBook for a short introduction to 
regular variation]. 
The limit is then a positively skewed stable distribution, 
whose scale parameter is $1$ if $b(n)$ is chosen accordingly
[see e.g. Section 3.7 in @MeerschaertSikorskii]. 
This distribution is most concisely defined via its Laplace transform
\begin{align} \label{theD}
\mathbf E[\exp(-sD)] = \exp(-s^\beta).
\end{align}
Moreover, the following functional limit theorem holds 
[see e.g. Remark 4.17 in @MeerschaertSikorskii]: 
\[
(W_1 + \ldots + W_{\lfloor ct \rfloor})/b(c) \overset{d}{\longrightarrow} D(t), \quad c \to \infty
\] 
with convergence in the Skorokhod $J_1$ topology. The limit
$D(t)$ is a stable subordinator, i.e. an increasing Levy process with
Laplace transform $\exp(-t s^\beta)$.


It is well known [see e.g. @limitCTRW] that the renewal
process then satisfies the functional limit
$$
N(ct)/ \tilde b(c) \stackrel{d}{\to} E(t) = \inf\{r: D(r) > t\}, 
\quad c \to \infty
$$
for a scaling function $\tilde b(c) \in {\rm RV}_\infty(\beta)$ which is asymptotically inverse to $b(c)$, in the sense of @seneta (p.20): 
$$
b(\tilde b(c)) \sim c \sim \tilde b(b(c)).
$$
[also see Prop 4.15 in @MeerschaertSikorskii]. 
The limit process $E(t)$ is called the _inverse stable subordinator_ [@invSubord].

## Magnitudes and Extreme Value Distributions

The extremal limit theorem then allows for an extension to functional 
(i.e. pathwise) limits: assume that the norming sequences $a(c)$ and 
$d(c)$ are as in Theorem GEV. Then 
$$
[M(ct) - d(c)] / a(c) \stackrel{d}{\to} A(t),
\quad c \to \infty.
$$
Here convergence holds weakly in Skorokhod's $J_1$ topology, and the limit
process $A(t)$ is an _extremal process_, with
finite-dimensional distributions given by
\begin{align}
\label{eq:fin-dim-A}
\mathbf P(A(t_i)\leq x_i,1\leq i \leq d) 
= F_A(\wedge_{i=1}^d x_i)^{t_1} 
F_A(\wedge_{i=2}^d x_i)^{t_2-t_1}
\ldots F_A(x_d)^{t_d-t_{d-1}},
\end{align}
where $F_A(x)$ is a GEV distribution [see e.g. @resnick2013extreme]. 

## CTRM limit

The CTRM $V(t)$ results from the running maximum $M(n)$ via a time change by the renewal process $n = N(t)$. This is also reflected in its corresponding limit process:

**Theorem MS1** [@MeerschaertStoev08]: 

: The CTRM process $V(t) = M(N(t))$ satisfies the following functional scaling limit in the Skorokhod $J_1$ topology: 
$$
[V(ct) - d(\tilde b(c))] / a(\tilde b(c)) \stackrel{d}{\to} 
A(E(t)), \quad c \to \infty.
$$

The distribution of the _hitting time_ of a level $\ell^*$ by the limit 
process $A(E(t))$ is also known, and we give it below for the convenience 
of the reader:

**Theorem MS2** [@MeerschaertStoev08]: 

: Let $F_A$ be the CDF of a GEV distribution, and let $A(t)$ be the
extremal process corresponding to $F_A$ via \eqref{eq:fin-dim-A}. 
For a given threshold $\ell^*$ in the support of $F_A$,
the hitting time
$$
B(\ell^*) = \inf\{t: A(E(t)) > \ell^*\} 
$$
is equal in distribution to $(-\log F_A(\ell^*))^{-1/\beta} X^{1/\beta} D$,
where $X \sim {\rm Exp}(1)$ and $D$ (defined in \eqref{theD}) are 
independent.

*Proof:*
Let the scaling functions $a(c)$ and $d(c)$ be as in Section 
\ref{magnitudes-and-extreme-value-distributions}, and assume WLOG 
$\ell = a(n) \ell^* + d(n)$ for some arbitrary but fixed $\ell^*$, out of the support of $A$. 
We first note that due to \eqref{eq:GEV}
\begin{equation} 
F_J (a(c) \ell^* + d(c))^c \stackrel{d}{\to} F_A(\ell^*), \text{ as } c \to \infty.
\end{equation}
\noindent Taking the logarithm on each side and using the relationship  $z-1 \sim \log(z)$ as $z \to 1$, we get
\begin{equation}
c (1-F_J(a(c) \ell^*+d(c))) \stackrel{d}{\to} - \log F_A(\ell^*).
\end{equation}
\noindent Hence we have 
\begin{equation}
c \cdot p \stackrel{d}{\to} - \log F_A(\ell^*) \label{eq:np_conv}
\end{equation}
\noindent as $\ell \uparrow x_R$.
Now we get


**Remark:**

: By the above theorem, the inter-exceedance times are i.i.d. and
approximately Mittag-Leffler distributed, which means that the exceedance
times form a *fractional Poisson process* [@Laskin2003]. 
Since the Mittag-Leffler distribution nests the exponential distribution 
(the special case where $\beta = 1$), the fractional Poisson process 
generalizes the standard Poisson process. 
As the threshold height increases, the threshold crossing events are 
effectively "thinned out", and the thinned (or rarefied) processes retain
the characteristics of a fractional Poisson process [@Gorenflo2010], 
with a growing scale parameter $b(1/p)$.

**Remark:**

: A fractional Poisson process can be represented as a
standard Poisson process $N(t)$, time-changed by an inverse stable 
subordinator $E(t)$ [@Meerschaert2010b]. 
This pattern can be made sense of in our context: 
The exceedance times for a standard extreme value process $A(t)$ form a 
standard Poisson process $N(t)$. Accordingly, the exceedance times 
of the CTRM limit $A(E(t))$ must be $N(E(t))$, a fractional Poisson 
process. 


\newpage

