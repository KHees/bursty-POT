---
title: "Statistical Inference for inter-arrival times of extreme events in bursty time series"
# titlerunning: "CTRE: POT for Bursty Time Series"
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
authors: 
- name: "Katharina Hees"
  address: TU Dortmund University
  email: hees@statistik.tu-dortmund.de
  
- name: "Smarak Nayak"
  address: National Australia Bank
  email: smarak.nayak@nab.com.au
  
- name: "Peter Straka*"
  address: UNSW Sydney
  email: p.straka@unsw.edu.au 
  
authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed 
  distribution. The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  This article proposes a new model for the _inter-exceedance times_ of thresholds;
  the threshold exceedances are modeled via the standard 
  Peaks Over Threshold (POT) method.
  For high thresholds and 
  infinite-mean waiting times, we show that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process of threshold
  exceedances.
  We provide graphical means of estimating model parameters and assessing 
  model fit. Along the way, we apply our inference method to a real-world
  bursty time series, and 
  show how the memory of the Mittag-Leffler distribution affects 
  the predictive distribution for the time until the next extreme event. 

bibliography: CTRMstats.bib
output: 
       rticles::elsevier_article:
                fig_caption: yes
                number_sections: true
                

params:
  tail: 0.8
  n: 10000

preamble: | 
  \usepackage{amssymb}
  \usepackage{natbib}
  \newtheorem{definition}{Definition}
  \newtheorem{theorem}{Theorem}

---

```{r get-rticles, eval=FALSE, include=FALSE, cache=TRUE}
# use this rticles version: 
devtools::install_github("rstudio/rticles")
# use the newest MittagLeffleR version:
devtools::install_github("UNSW-MATH/MittagLeffleR")
library(MittagLeffleR)
devtools::install_github("UNSW-MATH/CTRE")
library(CTRE)
setwd("~/GitHub/bursty-POT/article_springer")
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRE)
library(MittagLeffleR)
library(magrittr)
set.seed(12345)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour have received 
strong interest in the recent statistical physics literature 
[@Barabasi2005; @Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; 
@Min2010; @Karsai2011; @Bagrow2013]. They have been observed in the context 
of earthquakes, sunspots, neuronal activity and human communication [see 
@Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point process by @hawkes1971point), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
The Peaks-Over-Threshold model [POT, see e.g. @ColesBook] applies a
threshold to the magnitudes, and fits a Generalized Pareto distribution 
to the threshold exceedances. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@Hsing88]. 
Then as one increases the threshold and thus decreases the threshold 
crossing probability $p$, the Poisson process is rarefied, i.e. its 
intensity decreases _linearly_ with $p$ [see e.g. @beirlantBook]. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size increases and the threshold crossing
probability $p$ decreases, the fractional Poisson process is rarefied: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @Hees16; @Hees17], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Section 3.
We give a statistical procedure to estimate model parameters via stability plots 
in Section 5, but to set the stage we first discuss inference for the 
Mittag-Leffler distribution in Section 4. In Section 6, we discuss the memory property of the 
Mittag-Leffler distribution, and how it affects the predictive distribution 
for the time until the next threshold crossing event. A simulation study of the effectiveness of our statistical procedure is given in Section 7. In Section 8 we apply our method to a real data set. Finally we close with a discussion and conclusion in Section 8.
For all statistical computations we have used R [@R]. 
All code and data used for the analysis in this article has been organized into 
an R package `CTRE` (<https://github.com/strakaps/CTRE>).
The source code for the figures generated in this manuscript is 
available online at <https://github.com/strakaps/bursty-POT>. 


# Continuous Time Random Exceedances (CTRE)

As a model for extreme observations, we use a Marked Renewal Process (MRP):

\begin{definition}[MRP]
Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the \emph{waiting times}
and $J_k \in [x_L, x_R]$ as the \emph{event magnitudes}
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
If $W$ and $J$ are independent, the Marked Renewal Process is said to be \emph{uncoupled}. 
\end{definition}



We assume that the $k$-th magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on an MRP, we define the Continuous Time Random Exceedance model
(CTRE) as follows:

\begin{definition}[CTRE]
Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
Define the pair of random variables $(X(\ell), T(\ell))$ via 
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k.$$
By restarting the MRP at $\tau(\ell)$, inductively define the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$, 
called the "interarrival times" and the "exceedances", respectively.
The pair sequence $(T(\ell, n), W(\ell, n))_{n \in \mathbb N}$ is called 
a Continuous Time Random Exceedance model (CTRE). 
If the underlying MRP is uncoupled, then the CTRE is also called 
uncoupled. 
\end{definition}

```{r thresholdedBursty, message=FALSE, fig.height=3, fig.width=8, fig.cap="\\label{fig:thresholdedBursty}Exceedances (red) and Times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line)."}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)

times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
#times<-cumsum(rpareto(n,tail))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctre <- ctre(data.frame(times, magnitudes)) 
par(mfrow = c(1,2)) 
p1<-plot(sim_ctre, p = 0.01, main = "Simulated MRP") 
p2<-flares %>% ctre() %>% plot(p = 0.02, log = 'y', main = "HXRBS data")
library(gridExtra)
grid.arrange(p1, p2, nrow = 2)
```

In this article, we restrict ourselves to the uncoupled case, where $W$ and $J$ are independent. Then the two sequences $X(\ell, n)_{n \in \mathbb N}$ and $T(\ell, n)_{n \in \mathbb N}$ are independent as well. To see why, note that $X(\ell)$ is, in distribution, simply equal to $J | J > \ell$, independent of any waiting time $W_k$.  
Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top panel, where $W$ has a stable distribution with tail parameter $\beta =$ `r params$tail` (and skewness $1$ and location $0$), and where $J$ is from a standard Gumbel distribution. In the bottom panel, we plot a time series of solar flare intensities derived from a NASA dataset [@HXRBS] which we will later examine more closely (see Section 8). Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear continuously. The threshold exceedances, however, appear to have visually similar statistical behaviour in both models. Observations below a threshold are commonly discarded in Extreme Value Theory (POT approach); likewise, the CTRE model interprets these observations as noise and discards them.

# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state and prove the key theorem, see below. For an accessible introduction to regular variation and stable limit theorems, we recommend the book by @MeerschaertSikorskii.

\begin{theorem}
Let the waiting times $J_k$ be in the domain of attraction of a positively skewed sum-stable law with stability parameter $0 < \beta < 1$; more precisely,
\begin{align} \label{eq:stability}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
for a function $b(n)$ which is regularly varying at $\infty$ with parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$. Write $p := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p)} \to W_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$  
holds, where the Mittag-Leffler random variable $W_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sW_\beta)] = \frac{1}{1+s^\beta}.
$$ 
\end{theorem}

*Proof of Theorem:* We interpret the threshold crossing time $T(\ell)$ as the hitting time of the 
underlying CTRM (Continuous Time Random Maxima) or "max-renewal process", 
and then utilize a result by @MeerschaertStoev08. 
The running maximum process is defined as 
$$
M(c) := J_1 \vee \ldots \vee J_{\lfloor c \rfloor},
$$
and since we assume that the $J_k$ have a continuous distribution, there exist 
norming functions $a(c)$ and $d(c)$ such that 
$$
\mathbf P\left[ \frac{M(c) - d(c)}{a(c)} \le \ell^* \right] 
\longrightarrow F(\ell^*), \quad t \to \infty
$$
where $F$ is a generalized extreme value distribution, and $\ell^*$ is any 
value from the support of $F$. 
The CTRM process is then defined via 
$$
V(t) = M(N(t)), \quad t \ge 0
$$
where $N(t)$ is the renewal process associated with the waiting times 
$W_k$: 
$$
N(t) = \max\{n: W_1 + \ldots + W_n \le t\}.
$$
Now a key observation is that
$$
T(\ell) = \inf\{t: V(t) > \ell\}, 
$$
and that 
$$
T(\ell) > t \quad \text{ if and only if } \quad V(t) \le \ell.
$$
By [Theorem 3.1, @MeerschaertStoev08], we have the stochastic process 
convergence 
$$
\frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\stackrel{d}{\longrightarrow} Y(t), \quad t > 0.
$$
where $Y(t)$ is a time-changed ("subordinated") extremal process, and where 
$\tilde b(c)$ is a regularly varying norming function which is
_inverse_ to $b(c)$, in the sense that 
$b(\tilde b(c)) \sim c \sim \tilde b(b(c))$. 

Without loss of generality, we choose $\ell^*$ such that $F(\ell^*) = 1/e$, 
and let $\ell = a(\tilde b(c)) \ell^* + d(\tilde b(c))$. 
We may then calculate 
$$
\mathbf P\left[ \frac{T(\ell)}{b(1/p)} > t \right]
= \mathbf P[T(\ell) > b(1/p) t]
= \mathbf P[V(ct) \le \ell]
$$
where we have substituted $c = b(1/p)$. Moreover 
$$
\mathbf P[V(ct) \le \ell]
= \mathbf P\left[ \frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\le \frac{\ell - d(\tilde b(c))}{a(\tilde b(c))} \right]
\longrightarrow \mathbf P\left[ Y(t) \le \ell^* \right]
$$
Defining the hitting time of level $\ell^*$ by $Y(t)$ as 
$\xi_{\ell^*} := \inf\{t: Y(t) > \ell^*\}$,
we then have 
$$
P\left[ Y(t) \le \ell^* \right] = \mathbf P[\xi_{\ell^*} > t] 
= \mathbf P[(-\log F(\ell^*))^{-1/\beta} X^{1/\beta} D > t]
$$
by [Proposition 4.2, @MeerschaertStoev08], where $X$ is an exponential 
random variable with mean $1$. 
Using [Theorem 19.1, @Haubold11], we see that 
$X^{1/\beta} D \sim {\rm ML}(\beta, 1)$, concluding the proof. 
\qed  

For a scale parameter $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma W_\beta$. The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, for the purposes of applied statistics. 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11, and for algorithms, see e.g. the R package `MittagLeffleR`
[@MittagLeffleR].

\vspace{12pt}

**Remark.** If $\beta = 1$, the result of the Theorem above is standard, see e.g. 
Equation (2.2) by @Gut1999. @Anderson1987 derives a similar result with a 
different choice of scaling constant. 


# Model Choice and inference for the Mittag-Leffler distribution

The classical POT approach is based on the fact that exceedances above a high threshhold are asymptotically GPD distributed, hence a GPD distribution is fitted to the exceedances above a high enough threshhold. Due to the Theorem in the last Section we know that for high thresholds the times between exceedances are asymptotically Mittag-Leffler distributed in case of heavy tailed waiting times between the observations. Hence, before we talk about inference for the exceedances in the next section, we discuss inference for Mittag-Leffler distributions.

Historically, the first method proposed for the estimation of the Mittag-Leffler distribution parameters was the fractional moment estimator by @kozubowski2001. Unlike the first moments, the fractional moments of order $p$ for $p<\beta$ exist and are tractable. One drawback of this method is that constant priors for the tail parameter are needed for the calculation of the estimates. @Cahoy2010 proposed a moment estimator of the log transformed data, which does not require any prior. Furthermore, they performed simulation studies illustrating that the log-Moment outperforms the fractional moment estimator with respect to bias and root mean squared error (RMSE).

Due to the form of the density function of a Mittag-Leffler distribution there exists no closed form for the Maximum Likelihood estimator (MLE). In the R Package `MittagLeffleR` [@MittagLeffleR], Maximum Likelihood estimation is implemented via numerical optimization. The MLE slightly outperforms the log-moment estimator regarding bias and RMSE for big enough sample sizes, but is extremely computational intensive. Figure \ref{fig:MSE} shows that both estimators perform well, even for small sample sizes.

```{r MSE, echo=FALSE, fig.height=12, fig.cap="\\label{fig:MSE} MSE for sample sizes n=30, 100, 200 for the tail and scale estimations via log-moments and maximum likelihood estimation", out.width = '100%'}
knitr::include_graphics("MSE_n25_100_200.pdf")
```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers would intuitively give the highest importance to the tail behaviour of the distribution. Of course, one can also use established tail exponent estimators for the estimation of the parameter $\beta$ such as the Hill estimator
\begin{align*}
H_{k,n}= \frac{1}{k} \sum_{i=0}^{k-1} \log \frac{X_{n-i,n}}{X_{n-k,n}}. 
\end{align*}
However, these methods are statistically less efficient since they only use a portion of the information contained in the data, as mentioned by @kozubowski2001. Moreover, the hill estimator requires a tuning parameter, and only performs reliably well for distributions close to Pareto [see @Resnick97]. Figure \ref{fig:Hillplots} shows Hill plots for Mittag-Leffler simulated data, with varying sample sizes and tails. To deduce the correct tail parameter estimates from these plots is virtually impossible.

```{r Hillplots, echo=FALSE, fig.align="center", fig.cap="\\label{fig:Hillplots} Hillplots for simulated Mittag-Leffler distributed rv's with tail parameter 0.5 (two plots in the right column) and 0.8 (two plots in the left column) and sample sizes 200 (two plots in the lower row) and 1000 (two plots in the upper row). ", out.width = '90%'}
 knitr::include_graphics("Hillplots.pdf")
```


Since the exponential distribution is nested in the Mittag-Leffler family of distributions, an appropriate way to choose between a model with exponential and Mittag-Leffler inter-exceedance times seems to be a Likelihood ratio test. Although the two models are nested, the assymptotic distribution is not $\chi^2_1$-distributed, the classical Theorem of Wilk doesn't apply since under $H_0$ the parameter $\beta$ of the Mittag-Leffler distribution is equal to one and hence lies under $H_0$ on the boundary of the parameter space $(0,1]$. Nonetheless, one can perform a bootstrapped log-likelihood ratio test. In Figure \ref{Fig:LRT} one can see the power for the bootstrapped LRT for Mittag-Leffler distributions with different tail parameters. As expected the power gets smaller for tail parameters close to one, since the Mittag-Leffler distribution converges for $\beta \rightarrow 1$ to an exponential distribution. Consequently, for tail parameters close to one it is hard to differentiate a Mittag-Lefller distribution from an exponential. 


```{r likelihood-ratio-test}
flares_arrivals <- flares %>% ctre() %>% thin(k = 500) %>% interarrival()
mlmle_out <- mlmle(data = flares_arrivals)
```


Since the exponential distribution is nested in the Mittag-Leffler family of 
distributions, a Likelihood Ratio Test seems to be an appropriate way to choose 
between a model with exponential and Mittag-Leffler inter-exceedance times.
Although the two models are nested, the asymptotic distribution is not 
$\chi^2_1$-distributed, and Wilk's Theorem does not hold: under $H_0$, the 
parameter $\beta$ of Mittag-Leffler distribution is equal to $1$, and hence lies
on the boundary of the parameter space $(0,1]$. 
Instead, a valid approach is a bootstrapped log-likelihood ratio test 
(PUT REFERENCE HERE). 
Figure \ref{Fig:LRT} displays the power for the bootstrapped LRT for Mittag-Leffler distributions with varying tail parameters. As expected, the power decreases for tail parameters close to one, since the Mittag-Leffler distribution converges as $\beta \uparrow 1$ to an exponential distribution; it becomes hard to differentiate a Mittag-Lefller distribution from an exponential. 
(PUT ALL 4 CURVES INTO ONE PLOT)


```{r LRT power, echo=FALSE, fig.align="center", fig.cap="\\label{Fig:LRT} Power for bootstrapped LRT for different sample sizes", out.width = '80%'}
knitr::include_graphics("Plots_LRT_boot.pdf")
```

# Inference on Exceedance times


The Theorem in Section \ref{sec:scaling} implies that for a high 
threshold $\ell$ we may approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution, 
where the function $b(c)$ varies regularly at $\infty$ with parameter $1/\beta$.
Building on the POT (Peaks Over Threshold) method, we propose the following estimation procedure for the distribution of inter-exceedance time $T(\ell)$: 

1. For a range of thresholds $\ell$ near the largest order statistics, extract datasets of exceedance times $\{T(\ell, i)\}_i$.
  
2. For each choice of threshold $\ell$, fit a Mittag-Leffler distribution to the resulting dataset
  $\{T(\ell, i)\}_i$.  This results in the estimates $\{\hat\beta(\ell)\}_\ell$ and $\{\hat \sigma(\ell)\}_\ell$.
  
3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. Use $\hat \beta$ as an estimate for the tail      parameter $\beta$ of the Mittag-Leffler distribution of exceedance times. 
  

4. Approximate $p \approx |\{k: J_k > \ell\}| / n$. 
  Recall that $b(c)$ is regularly varying with parameter $1/\beta$, and 
  hence has the representation $b(c) = L(c) c^{1/\beta}$ for some 
  slowly varying function $L(c)$. 
  Assuming that the variation of $L(c)$ is negligible, we hence 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ is expected to stabilize around a constant 
  $\hat \sigma_0$. 
  We then use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 

The above approach benefits from the following
practical adjustments (compare with Figure \ref{fig:flares}):

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
  
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 

* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by the multiplicative constant $n^{1/\hat \beta}$, 
  but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0),
\end{align*}
where $\ell$ equals the $k$-th order statistic.
For quick estimates of the Mittag-Leffler parameters we have used 
the method of log-transformed moments [@Cahoy2013].
We have verified the validity of our estimation algorithm  via simulations, 
see the appendix. 



# Predicting the time of the next threshold crossing

According to Figure \ref{fig:flares}, for a threshold $\ell$ at the $k$-th order 
statistic, the fitted threshold exceedance time distribution is 
$$
T(\ell) \sim {\rm ML}(\beta, k^{-1/\beta} \sigma_0), 
$$
where $\beta = 0.85$ and $\sigma_0 = 3.0 \times 10^7 {\rm sec}$. 
Unlike the exponential distribution, the Mittag-Leffler distribution is not memoryless, and the probability density of the time $t$ until the next threshold crossing will depend on the time $t_0$ elapsed since the last threshold crossing.
This density equals 
$$
p(t|\beta, \sigma_0, \ell, t_0) = \frac{f(t + t_0 | \beta, k^{-1/\beta} \sigma_0)}{\mathbf P[T_\ell > t_0]}
$$
where $f(\,\cdot\, | \beta, k^{-1/\beta} \sigma_0)$ is the probability density of ${\rm ML}(\beta, -k^{1/\beta} \sigma_0)$. 
The more time has passed without a threshold crossing, the more the probability distribution shifts towards larger values for the next crossing
(see Figure \ref{fig:hazard}, left panel). The hazard rate 
$$
h(t) = \frac{f(t| \beta, k^{-1/\beta} \sigma_0))}{\int_t^\infty f(\tau| \beta, k^{-1/\beta} \sigma_0))\,d\tau}
$$
represents the risk of a threshold crossing per unit time, and is a decreasing function for the Mittag-Leffler distribution. 
```{r hazard, fig.height=4, fig.cap="Left: Conditional distribution of time until next threshold crossing, depending on elapsed time $t_0$ since last crossing ($\\beta = 0.8$, $\\sigma_0 = 1$). Right: Hazard rate depending on tail parameter $\\beta$.\\label{fig:hazard}"}
tail <- 0.7
scale <- 1
t_0 <- c(0, 1, 10)
from <- 0.1
to <- 100 * scale
xx <- exp(seq(from = log(from), to = log(to), length.out = 100))
par(mfrow = c(1,2))
plot(xx, rep(1, length(xx)), ylim = c(0.001,1), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'p')
for (k in 1:length(t_0)) {
  cond <- pml(q = t_0[k], tail = tail, scale = scale, lower.tail = FALSE)
  yy <- dml(x = xx + t_0[k], tail = tail, scale = scale) / cond
  lines(xx,yy, col = k+1, lty = k)
}
legend("bottomleft", c("t_0 = 0", "t_0 = 1", "t_0 = 10"), col = 2:4, lty = 1:3)

betas <- c(0.7, 0.8, 0.95, 0.99)
t_0 <- 1
plot(xx, rep(1, length(xx)), ylim = c(0.001,2), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'h')
for (k in 1:length(betas)) {
  yy <- dml(x = xx, tail = betas[k], scale = scale) / pml(
    q = xx,
    tail = betas[k],
    scale = scale,
    lower.tail = FALSE
  )
  lines(xx,yy, col = k+1, lty = k)
}
legend("bottomleft", c("beta = 0.7", "beta = 0.8", "beta = 0.95", "beta = 0.99"), col = 2:5, lty = 1:4)

```
The closer $\beta$ is to $1$, the more the hazard rate mimics that of an 
exponential distribution (a constant function, see Figure \ref{fig:hazard}, 
right panel). 


# Simulation study

To test our inference method via stability plots, we have simulated 
independent waiting time and magnitude pairs $(W_k, J_k)$ for three different
situations: stable waiting times, Pareto waitings times and Exponential waiting 
times. In order to have exact 
analytical values available for $\beta$ and $\sigma_0$, a distribution for 
$W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:stability} is known. 
If we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{eq:stability}, 
then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation [see e.g. the vignette on parametrisation in @MittagLeffleR]
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. 

```{r make-caption}
caption = "Tail and scale estimates for simulated data, with waiting times drawn from the stable distribution $S_\\beta(\\cos(\\pi \\beta/2)^{1/\\beta}, +1, 0)$ with $\\beta = 0.8$. Dashed lines are 95\\% confidence intervals, dotted lines are the known theoretical values ($0.8$ and $10000^{1/0.8}$). \\label{fig:sim}"
```


<!-- ```{r simulated-example, message=FALSE, warning=FALSE, fig.cap=caption} -->
<!-- k_max <- 500 -->

<!-- thin_sim_ctre <- thin(ctre = sim_ctre, k = k_max) -->
<!-- # par(mfrow=c(1,2)) -->
<!-- MLestimates(ctre = thin_sim_ctre, tail = params$tail, scale = n^(1/params$tail)) -->
<!-- ``` -->

By the Theorem, the distribution 
of $T(\ell)$ is approximately 
$$
{\rm ML}(\beta, p^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta}),
$$
which means 
$\sigma_0 = n^{1/\beta}$. we have chosen $\beta=1$ in the stable as well in the
Pareto case. Figure \ref{fig:Ex1figs} displays plots of $\hat \beta(k)$ vs. $k$ for
the first example with stable distributed waiting times. In the left picture we 
used the log moment estimator, in the middle picture maximum likelihood estimates 
(both applied to the inter-exceedance times) and for the right picture hill 
estimators applied to the inter-arrival times. Recall that $k$ is the index of the 
order statistics of $J_k$ at which the threshold $\ell$ is placed.

```{r Ex1figs, echo=FALSE,fig.height=7,fig.cap="\\label{fig:Ex1figs} Stability Plots for m=100 simulation runs for Example 1 (stable distributed waiting times, true tail parameter =0.8). The grey lines, the red line and the blue lines are the log Moment, the MLE and the hill estimator, repectively, for different $k$'s on the x-axis. The dark lines in each picture are the means of the concerning estimators for different $k$'s.", fig.show='hold', out.width = '32%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex1_Tail08_logMoms.pdf","SimuStudy_StabilityPlots_Ex1_Tail08_mles.pdf","SimuStudy_StabilityPlots_Ex1_Tail08_hill.pdf"))
```
Figure \ref{fig:Ex2figs} shows the estimates for different $k$'s and for the
different estimators for the tail parameter $\beta$. Again one can see that 
the Hill estimator has a higher variance. 

```{r Ex2figs, echo=FALSE,fig.height=7,fig.cap="\\label{fig:Ex2figs} Stability Plots for m=100 simulation runs for Example 2 (Pareto distributed waiting times, true tail parameter =0.8). The grey lines, the red line and the blue lines are the log Moment, the MLE and the hill estimator, repectively, for different $k$'s on the x-axis. The dark lines in each picture are the means of the concerning estimators for different $k$'s.", fig.show='hold', out.width = '32%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex2_Tail08_logMoms.pdf","SimuStudy_StabilityPlots_Ex2_Tail08_mles.pdf","SimuStudy_StabilityPlots_Ex2_Tail08_hill.pdf"))
```
To show how the different estimates behave in the case where $\beta=1$
(the exponential case), we simulated in a last example exponentially distributed
waiting times.

```{r Ex3figs, echo=FALSE,fig.height=7,fig.cap="\\label{Fig:Ex3figs} Stability Plots for m=100 simulation runs for Example 3 (Exponentially distributed waiting times, true tail parameter =0.8). The grey lines, the red line and the blue lines are the log Moment, the MLE and the hill estimator, repectively, for different $k$'s on the x-axis. The dark lines in each picture are the means of the concerning estimators for different $k$'s.", fig.show='hold', out.width = '32%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex3_logMoms.pdf","SimuStudy_StabilityPlots_Ex3_mles.pdf","SimuStudy_StabilityPlots_Ex3_hill_times.pdf"))
```

# Data example

We now want to apply the proposed method to a real data example, the solar flare data which was already mentioned in Section 1 and can be seen in Figure \ref{fig:thresholdedBursty}. The data were extracted from the "complete Hard X Ray Burst Spectrometer event list", a comprehensive reference for all measurements of the Hard X Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 events were detected, with the "vast  majority being solar flares". The list includes the start time, peak time, duration, and peak rate of each event. We have used "start time" as the variable for event times, and "peak rate" as the variable for event magnitudes. 
 
Before we apply the POT approach described in Section 5 to the solar flare data, we first have to check if all model assumptions are full-filled. The CTRE model is based on three main assumptions, which are repeated below. For each assumption, we suggest one means of checking if it holds: 

i.i.d.:

: After removing the "noise observations" below the smallest threshold 
  $\ell_0$, the pair sequence $(T(\ell_0, i), X(\ell_0,i))$ is i.i.d. 
  An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  

Uncoupled:

: Each $T(\ell, i)$ is independent of each $X(\ell, i)$. We propose an empirical copula
  plot to check for any dependence. 
  
  

${\rm ML}(\beta, \sigma)$ distribution of $T(\ell, i)$:

: Apply a cutoff at the lowest threshold $\ell_0$, 
  extract the threshold crossing times, 
  and create a QQ Plot for the Mittag-Leffler distribution. 
  Use a log-Moment estimate of the tail parameter for the theoretical / population 
  quantiles of the plot.


Figures \ref{fig:flare-diagnostics-1} and \ref{fig:flare-diagnostics-2} show the diagnostic plots for a minimum threshold chosen at the 200th order statistic. There is some residual autocorrelation for the sequence of threshold exceedance times that is not accounted for by the CTRE model.  

```{r flare-diagnostics-1, fig.height=7, fig.cap="Diagnostic plots for the solar flare data: auto-correlation function.\\label{fig:flare-diagnostics-1}"}
flares_ctre <- flares %>% ctre() %>% thin(k = 150)
acf(flares_ctre)
```


```{r flare-diagnostics-2, fig.height=4.5, fig.width=8, fig.cap="Diagnostic plots for the solar flare data: empirical copula and QQ Plot. \\label{fig:flare-diagnostics-2}"}
par(mfrow = c(1,2))
empcopula(flares_ctre)
flares_ctre %>% interarrival() %>% mlqqplot(log = 'xy', tail = 0.85, main = "Mittag-Leffler QQ Plot")
```

Figure \ref{fig:flares} shows the stability plots for the solar flare data, on the 
left for the tail parameter and on the right for the scale parameter. Dotted lines 
show 95% confidence intervals, which are derived from the asymptotic normality of 
the log-moments estimators [@Cahoy2013] and the $\delta$-method 
[see @MittagLeffleR], 
dashed lines show the actual values of $\beta$ resp.\ $\sigma_0$. The stability 
plot for the tail stabilizes nicely round about 0.85 (dotted line), while it is a 
little bit harder to deduce an estimate for the scale parameter. Howerever, the 
stability plot for the scale parameter seems to stabilize round about $3 \times 
10^7$.  

```{r solar-flare-tail-scale, message=FALSE, fig.height=4.5, fig.width=8, fig.cap="\\label{fig:flares}Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset. Dotted horizontal lines are at $\\beta = 0.85$ and $\\sigma_0 = 3 \\times 10^7$ seconds $\\approx 0.95$ years."}
thin_flares_ctre <- flares %>% ctre() %>% thin(k = 700)
par(mfrow=c(1,2))
MLestimates(thin_flares_ctre, tail = 0.9, scale = 3 * 1E7)
```

The fit with a Mittag-Leffler distribution ($\beta = 0.85$) is good, though there are signs that the power-law tail tapers off for very large inter-threshold crossing times. There is no apparent dependence between threshold exceedance times and event magnitudes seen in the copula plot. We also counduct a bootstrapped LRT for the null hypothesis of exponential distributed inter-arrival times and received a $p$-value of $p<0.01$. 


# Discussion & Conclusion

We have extended the POT (Peaks over Threshold) model, a mainstay of extreme value theory, to "bursty" time series, which have been studied 
intensively in statistical physics. Burstiness is characterized by power-law waiting times between events, and we have shown that the Mittag-Leffler distribution arises naturally as a scaling limit for the inter-exceedance times of high thresholds. Moreover, we have derived the following non-linear scaling behaviour: $\sigma \sim p^{-1/\beta}$, where $\sigma$ is the scale parameter of the distribution of threshold 
exceedance times, $p$ is the fraction of magnitudes above the threshold, and $\beta$ the exponent of the power law. 
This "anomalous" scaling behaviour in the bursty setting entails two phenomena: 

i) a heavy tail of the interarrival time distribution of threshold crossings (long rests), and 

ii) a high propensity for more threshold crossing events immediately after each threshold crossing event (bursts). 

The Mittag-Leffler distribution captures both phenomena, due to its heavy tail as well as its stretched exponential (peaked) asymptotics for small times. It generalizes the exponential distribution, and in the solar flare data example, this generalization is warranted, because the likelihood-ratio test is strongly significant. 

When we introduced the CTRE model, we assumed that all events are i.i.d. This assumption is likely sufficient but not necessary for our limit theorem to hold. Moreover, any data below a (minimum) threshold $\ell_0$ is discarded for CTREs, and hence need not satisfy the i.i.d. assumption.For the purposes of statistical inference, we merely require that the inter-threshold-crossing times are i.i.d. 

The bursty CTRE approach to model "non-Poissonian" threshold crossing times should be contrasted with the (now standard) approach of clusters of extremes, see e.g. @ferro2003inference. In this approach, i.i.d. event sequences of magnitudes are generalized to stationary sequences of
event magnitudes (subject to a mixing condition). The two approaches are fundamentally different: A clustering model assumes that each event 
belongs to one particular (latent) group of events. For bursts, however, the aim is to identify an underlying scale-free pattern in the event 
dynamics, which is often characteristic of complex systems. It is an interesting open problem to develop quality criteria, based
e.g. on measures of surprise [@Lee15], which guide an applied statistician in the choice between a clustering and a CTRE approach for a particular problem. Moreover, we believe it may be possible to unify the two approaches by considering CTREs based on MRPs with a _stationary_, rather than i.i.d., sequence of magnitudes. 

Finally, a purely scale-free pattern for event times may be too rigid as an 
assumption for some bursty time series, because often the heavy-tailed character of the inter-arrival time
distribution does not hold at all time scales; rather, it applies at short and intermediate time scales, and is truncated (or tempered, 
reverting to an exponential distribution) at very long time scales [see e.g. @MeerschaertRoyQin; and @Aban06]. In such situations, a "tempered" Mittag-Leffler distribution may provide a more realistic fit, which we aim to introduce in follow-up work. 

# Acknowledgements {-}

The authors would like to thank Prof. Peter Scheffler for insights on stochastic process limits for CTRMs, Roloand Fried for discussion according the statistical methods and Gurtek Gill who helped create the MittagLeffleR R-package. 

\newpage

# Appendix {-}

```{r Ex1figsScale, echo=FALSE,fig.height=7,fig.cap="\\label{Fig:Ex1figsScale} Stability Plots for the scale parameter for Example 1 (stable distributed waiting times, true scale parameter = 1).", fig.show='hold', out.width = '40%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex1_Scales_logMoms.pdf","SimuStudy_StabilityPlots_Ex1_Scales_mles.pdf"))
```

```{r Ex2figsScale, echo=FALSE,fig.height=7,fig.cap="\\label{Fig:Ex2figsScale} Stability Plots for the scale parameter m=100 simulation runs for Example 2 (stable distributed waiting times, true scale parameter = 1).", fig.show='hold', out.width = '40%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex2_Scales_logMoms.pdf","SimuStudy_StabilityPlots_Ex2_Scales_mles.pdf"))
```

```{r Ex3figsScale, echo=FALSE,fig.height=7,fig.cap="\\label{Fig:Ex3figsScale} Stability Plots for the scale parameter for m=100 simulation runs for Example 3 (stable distributed waiting times, true scale parameter = 1).", fig.show='hold', out.width = '40%'}
knitr::include_graphics(c("SimuStudy_StabilityPlots_Ex3_Scales_logMoms.pdf","SimuStudy_StabilityPlots_Ex3_Scales_mles.pdf"))
```
\newpage

# References {-}

