---
title: "Statistical Inference for inter-arrival times of extreme events in bursty time series"
# titlerunning: "CTRE: POT for Bursty Time Series"
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
author: 

- name: "Katharina Hees"
  affiliation: a
  email: "hees@statistik.tu-dortmund.de"
  correspondence: true
  
- name: "Smarak Nayak"
  affiliation: b
  email: "smarak.nayak@nab.com.au"
  
- name: "Peter Straka"
  affiliation: c
  email: "straka.ps@gmail.com"
  
address:

- code: a
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

- code: b
  address: "National Australia Bank, Melbourne, Australia"
    
- code: c
  address: "School of Mathematics and Statistics, UNSW, Sydney, Australia"
    
corrauth:
  name: "Katharina Hees"
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed distribution. The set of event times is fractal-like, 
  being dense in some time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  A new model for the _inter-exceedance times_ of events 
  above high thresholds is proposed. For high thresholds and 
  infinite-mean waiting times, it is shown that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process of threshold
  exceedances.
  Graphical means of estimating model parameters and assessing 
  model fit are provided. Along the way, the inference method gets applied to a real-world
  bursty time series, and it is shown how the memory of the Mittag-Leffler distribution affects 
  the predictive distribution for the time until the next extreme event. 

bibliography: CTRMstats.bib
csl: elsevier-harvard.csl
output:
  html_document: default
  rticles::elsevier_article:
    number_sections: true
    fig_caption: yes
                
params:
  tail: 0.8
  n: 10000

header-icludes: \usepackage{amssymb,natbib}

---

```{r get-rticles, eval=FALSE, include=FALSE, cache=TRUE}
# use this rticles version: 
devtools::install_github("rstudio/rticles")
# use the newest MittagLeffleR version:
devtools::install_github("strakaps/MittagLeffleR")
library(MittagLeffleR)
devtools::install_github("strakaps/CTRE")
library("CTRE")
library(CTRE)
install.packages("here")
library(here)
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRE)
library(MittagLeffleR)
library(magrittr)
library(gridExtra)
library(ggplot2)
library(dplyr)
library(forecast)
set.seed(12345)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour in terms of the occurrence of events have received strong interest in the recent statistical physics literature [@Barabasi2005;@Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; @Min2010; @Karsai2011;@Bagrow2013]. They have been observed in the context of earthquakes, sunspots, neuronal activity and human communication [see @Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point process by @hawkes1971point), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
The Peaks-Over-Threshold model [POT, see e.g. @ColesBook] applies a
threshold to the magnitudes, and fits a Generalized Pareto distribution 
to the threshold exceedances. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@Hsing88]. 
Then as one increases the threshold $\ell$ and thus decreases the threshold 
crossing probability $p_{\ell}$, the Poisson process is thinned, i.e. its 
intensity decreases _linearly_ with $p_{\ell}$ [see e.g. @beirlantBook]. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size $\ell$ increases and the threshold crossing
probability $p_{\ell}$ decreases, the fractional Poisson process is thinned: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @hees2016joint; @hees2017coupled], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Section 3.
We give a statistical procedure to estimate model parameters via stability plots 
in Section 5, but to set the stage we first discuss inference for the 
Mittag-Leffler distribution in Section 4. A simulation study of the effectiveness of our statistical procedure is given in Section 6. In Section 7 we apply our method to a real data set.  In Section 8, we discuss the memory property of the  Mittag-Leffler distribution, and how it affects the predictive distribution for the time until the next threshold crossing event. Finally we close with a discussion and conclusion in Section 9.
For all statistical computations we have used R [@R]. 
All code and data used for the analysis in this article has been organized into 
an R package `CTRE` (<https://github.com/strakaps/CTRE>).
The source code for the figures generated in this manuscript is 
available online at <https://github.com/strakaps/bursty-POT>. 


# Continuous Time Random Exceedances (CTRE)

As a model for extreme observations, we use a Marked Renewal Process (MRP):

**Definition (MRP):** 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random variables, where the $W_k > 0$ are interpreted as the *waiting times* 
and $J_k \in \mathbb{R}$ as the *event magnitudes*. If $W$ and $J$ are independent, the Marked Renewal Process is said to be *uncoupled*. 


In the following we denote with $x_L \in [-\infty, +\infty)$ and $x_R \in (-\infty, +\infty]$ the left and right endpoint of the distribution of $J$. We assume that the $k$-th magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on a MRP, we define the Continuous Time Random Exceedance model
(CTRE) as follows:

**Definition (CTRE):** 

: Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
Define the pair of random variables $(X(\ell), T(\ell))$ via 
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k.$$
By restarting the MRP at $\tau(\ell)$, inductively define the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$, 
called the "inter-arrival times" and the "exceedances", respectively.
The pair sequence $(X(\ell, n), T(\ell, n))_{n \in \mathbb N}$ is called 
a Continuous Time Random Exceedance model (CTRE). 
If the underlying MRP is uncoupled, then the CTRE is also called 
uncoupled. 


```{r thresholdedBursty, message=FALSE, fig.height=6, fig.width=7,out.width='70%',fig.align='center',fig.cap="\\label{fig:thresholdedBursty} Exceedances (red) and times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line). Upper picture: Simulated data with stable distributed waiting times. Lower picture: Solar flares during 1982."}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctre <- ctre(data.frame(times, magnitudes)) 
p1<-plot(sim_ctre, p = 0.01, main = "Simulated MRP") + 
  ggtitle("Simulated MRP") +
   theme(plot.title = element_text(hjust = 0.5))
p2<-flares %>% ctre() %>% plot(p = 0.02, log = 'y', main = "HXRBS data") +
  ggtitle("HXRBS data")+
   theme(plot.title = element_text(hjust = 0.5))
grid.arrange(p1,p2)
```

In this article, we restrict ourselves to the uncoupled case, where $W$ and $J$ are independent. Then the two sequences $X(\ell, n)_{n \in \mathbb N}$ and $T(\ell, n)_{n \in \mathbb N}$ are independent as well. To see why, note that $X(\ell)$ is, in distribution, simply equal to $J - \ell | J > \ell$, independent of any waiting time $W_k$.  
We assume for the rest of the article, that the magnitudes $(J_i)_{i \in \mathbb{N}}$ belong to the the max-domain of attraction of some non-degenerate distribution. This means there exist $a_n>0$ and $d_n \in \mathbb{R}$ such that 
\begin{align} \label{assumptionJs}
a_n^{-1}(J_1 \vee \ldots \vee J_n -d_n) \Rightarrow A \text{ as } n \rightarrow \infty.
\end{align}
Hence, the distribution of $A$ is a generalized extreme value distribution (GEV) whose distribution function is given by 
$$ F(x;\xi) = \begin{cases}\exp(-(1+\xi x)_+^{-1/\xi}) & \xi\neq0 \\ \exp(-\exp(-x)) & \xi = 0\end{cases}$$ 
where $(.)_+:= \max\{0,.\}$.

The GEV is subdivided into the Gumbel ($\xi=0$), the Weibull ($\xi<0$) and the Fréchet ($\xi>0$) family of distributions.  

Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top panel, where $W$ has a stable distribution with tail parameter $\beta =$ `r params$tail` (and skewness $1$ and location $0$), and where $J$ is from a standard Gumbel distribution. In the bottom panel, we plot a time series of solar flare intensities derived from a NASA dataset [@HXRBS] which we will later examine more closely (see Section 7). Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear continuously. The threshold exceedances, however, appear to have visually similar statistical behaviour in both models. Observations below a threshold are commonly discarded in Extreme Value Theory (POT approach); likewise, the CTRE model interprets these observations as noise and discards them.

# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state and prove the key theorem, which is founded on the concept of regular variation. A Borel-measurable function $f:\mathbb (0,\infty) \to (0,\infty)$ is said be "regularly varying at $\infty$ with parameter (or "index") $\rho$ if 

$$
\underset{x\rightarrow \infty}{lim}\frac{f(\lambda x)}{f(x)} = \lambda^\rho \quad \text{ for all } \lambda > 0.
$$

For more details regular variation and stable limit theorems, we recommend the book by @MeerschaertSikorskii.

**Theorem:** 

: For the magnitudes $J_k$ assumption \eqref{assumptionJs} holds. Furthermore, let the waiting times $W_k$ be in the domain of attraction of a positively skewed sum-stable law with stability parameter $0 < \beta < 1$; more precisely,
\begin{align} \label{eq:stability}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
for a function $b(n)$ which is regularly varying at $\infty$ with parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$, $s > 0$. Write $p_{\ell} := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p_{\ell})} \to Z_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$
holds, where the Mittag-Leffler random variable $Z_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sZ_\beta)] = \frac{1}{1+s^\beta}.
$$ 


*Proof of Theorem:* 	Due to assumption \eqref{assumptionJs}, it follows that
	\begin{align*}
	P\left(\frac{M(c)-d(c)}{a(c)} \leq x\right) \rightarrow F(x) := F(x,\xi) \text{ as } c \rightarrow \infty,
	\end{align*}
	where $x$ is any value from the support of $F$. Then
	\begin{align*}
	  F(xa(c)+d(c))^{\lfloor c \rfloor} &\rightarrow F(x) \text{ as } c \rightarrow \infty,\\
      \Rightarrow  \lfloor c \rfloor \log F(\ell_c)  &\rightarrow \log F(x)\text{ as } c \rightarrow \infty,
	\end{align*}
	with $\ell_c:=xa(c)+d(c)$. Furthermore, since $\log(1-x) \sim -x$ for small $x$ it follows
    \begin{align}
      c \cdot p(\ell_c) \rightarrow -\log F_A(x)  \text{ as } c \rightarrow \infty,\label{eq:lplconv}
    \end{align}
	 with $p(\ell_c):= 1-F(\ell_c)$. Since $\tau(\ell_c) \sim Geo(p(\ell_c))$ and \eqref{eq:lplconv}
	it follows that $\tau(\ell_c)/c$ converges to an Exponential distributed random variable,
	\begin{align*}
	\frac{\tau(\ell_c)}{c} \Rightarrow E  \text{ as } c \rightarrow \infty
	\end{align*}
	 with inverse mean $\lambda:=-\log F_A(x)$. Due to
	\begin{align*}
	S(c):= \sum_{i=1}^{\lfloor c \rfloor} \frac{W_i}{b(c)} \Rightarrow D \ \text{ as } c \rightarrow \infty,
	\end{align*}
    it follows with Gnedenko's transfer theorem (see @gnedenko1983limit), that
	\begin{align}
	\sum_{i=1}^{ \tau(\ell_c)} \frac{W_i}{b(\ell_c)}  \Rightarrow Z\ \text{ as }  c \rightarrow \infty, \label{TheoGutArg}
	\end{align}
	where the distribution of $Z$ has the characteristic function
	\begin{align}
    \Psi(s) &= \int_0^{\infty} (\Phi_D(s))^{y} F_E(dy) \nonumber\\
    &= \int_0^{\infty} \frac{1}{1-\log(\Phi_D(s))/\lambda} \nonumber\\
    &= \frac{1}{1+s^{\beta}\lambda^{-1}}
	\end{align}
    where $\Phi_D(s) = \exp(-s^\beta)$ is the Laplace transform of $D$ 
    and  $F_E(dy)$ is the distribution function of $E$. Hence, $Z$ is Mittag-Leffler distributed with parameter $\lambda^{-1/\beta}$. Rewriting
	\begin{align*}
    \sum_{i=1}^{ \tau(\ell_c)} \frac{W_i}{b(1/p(\ell_c))} = \left(\sum_{i=1}^{ \tau(\ell_c)} \frac{W_i}{b(c) }\right) \frac{b(c)}{b(1/p(\ell_c))}  
	\end{align*}
	and
	\begin{align*}
	\frac{b(c)}{b(1/p(\ell_c))} = \frac{b(c)}{b(c/(p(\ell_c)c))} \sim (p(\ell_c) \cdot c)^{1/\beta} \rightarrow \lambda^{1/\beta} \text{ as } c \rightarrow \infty,
	\end{align*}
	the second factor converges to $\lambda^{1/\beta}$, and it follows that
	 $Z \sim ML(\beta,1)$. Since $c \rightarrow \infty$ is equivalent to $\ell \uparrow x_R$, the assertion follows with $\ell:=\ell_c$ and $p_\ell:=p(\ell_c)$.
\qed

For a scale parameter $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma Z_\beta$. The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$ with mean $\sigma$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, for the purposes of applied statistics. 

We caution the reader that, somewhat confusingly, there is another distribution
called the "light-tailed" Mittag-Leffler distribution.  This is in fact the 
limiting distribution of the renewal process $N(t)$ above (see @limitCTRW). 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11, and for algorithms, see e.g. the R package `MittagLeffleR`
[@MittagLeffleR].


**Remark:**

: If $\beta = 1$, the result of the Theorem above is standard, see e.g. 
Equation (2.2) in @Gut1999. In @Anderson1987  a similar result is shown with a different choice of scaling constant. [@MeerschaertStoev08] proofed a limit theorem for the maxima of iid random variables separated by infinite mean waiting times. They showed that the duration time of the limit process is Mittag-Leffler distributed. [@Basrak2014] described the asymptotic distribution under similar assumptions of all upper orders statistics using point processes.

**Remark:**

: When $0 < \beta < 1$, the renewal process $N(t)$ is _not stationary_, 
and hence the results by @Hsing88 on the exceedances of stationary sequences
do not apply. 


# Model Choice and inference for the Mittag-Leffler distribution{#sec:ML}

The classical POT approach is based on the fact that exceedances above a high threshold are asymptotically GPD distributed, hence a GPD distribution is fitted to the exceedances above a high enough threshold. As this approach is by now well-established in extreme value theory, we do not discuss it any further. Instead, this article focuses on our new contribution: the modelling of inter-exceedance times. For literature pointing to POT see e.g. @smith1984threshold; @leadbetter1991basis; @davison1990models; @beirlantBook Ch.5.3; @embrechts2013modelling Ch. 6.5.; @ColesBook Ch.4.

Due to the Theorem in the last Section we know that for high thresholds the times between exceedances are asymptotically Mittag-Leffler distributed in case of heavy-tailed waiting times between the observations. In this article we propose to model inter-exceedance times in a similar fashion as magnitudes in the classical POT approach, more precisely to fit a Mittag-Leffler distribution to the inter-exceedance times via stability plots. Hence, before we discuss inference for the inter-exceedance times in the next section, we first discuss inference for Mittag-Leffler distributions.

Historically, the first method proposed for the estimation of the Mittag-Leffler distribution parameters was the fractional moment estimator by @kozubowski2001. Unlike the first moments, the fractional moments of order $p$ for $p<\beta$ exist and are tractable. One drawback of this method is that constant priors for the tail parameter are needed for the calculation of the estimates. @Cahoy2010 proposed a moment estimator of the log-transformed data, which does not require any prior. Furthermore, they performed simulation studies illustrating that the log-Moment outperforms the fractional moment estimator with respect to bias and root mean squared error (RMSE).

Due to the form of the density function of a Mittag-Leffler distribution there exists no closed form for the Maximum Likelihood estimator (MLE). In the R Package `MittagLeffleR` [@MittagLeffleR], Maximum Likelihood estimation is implemented via numerical optimization. The MLE slightly outperforms the log-Moment estimator regarding bias and RMSE for big enough sample sizes, but is extremely computationally intensive. Figure \ref{fig:MSE} shows that both estimators perform well, even for small sample sizes. For smaller tails both estimators show an increasing RMSE for the scale estimation due to an increasing variance. This results from the fact that in case of very small tails, single very large values can occur. 

```{r MSE, echo=FALSE,warning=FALSE, fig.height=7,fig.width=8,fig.align="center", fig.cap="\\label{fig:MSE} RMSE for the estimation of tail (left column) and scale (right column) parameters via log-Moment estimator and MLE of a Mittag-Leffler sample with varying sample size n=25, 100, 200, varying tails on the x-axis and fixed scale equal to one, based on 5000 simulation runs.", out.width = '90%'}
load(here::here("article_springer", "article_springer_files", "ML_estim_simu","tbl_ML_estim.RData"))
  n.labs <-c("n=25", "n=100", "n=200")
  names( n.labs ) <-  c("25", "100", "200")
tbl_ML_estim %>% filter(method=="logMom" | method=="ML")%>%
  filter(n == "25" | n == "100" | n=="200") %>%
  filter(true.scale == "1") %>% 
  ggplot(aes(true.tail, rmse, colour = method, group=method)) + 
  geom_line() + geom_point() + 
  facet_wrap(c("n","param"), scales = "free", ncol = 2, labeller = labeller(n = n.labs)) + 
  scale_color_manual(values=c("red", "blue"),name = "Method", labels = c("log-Moment", "MLE")) + ggtitle("RMSE for log-Moment and MLE") +
   theme(plot.title = element_text(hjust = 0.5))
  
```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers would intuitively give the highest importance to the tail behaviour of the distribution. Of course, one can also use established tail exponent estimators for the estimation of the parameter $\beta$ such as the Hill estimator [@hill1975simple] based on the $r+1$ upper order statistics
\begin{align}\label{eq:Hill}
H_{r,n}=\left[ \frac{1}{r} \sum_{i=0}^{r} \log \frac{X_{(i)}}{X_{(r+1)}}\right]^{-1}, 
\end{align}
where $X_{(1)} \geq X_{(2)} \geq \ldots \geq X_{(n)}$ denote the order statistics in decreasing order of a sequence $X_1,\ldots,X_n$. The Hill estimator only performs reliably well for distributions close to Pareto [see @Resnick97]. It heavily depends on the choice of $r$ in \eqref{eq:Hill}, and hence on the number of order statistics entering \eqref{eq:Hill}.  Figure \ref{fig:Hillplots} shows 100 Hill plots (grey thin lines) for simulated Mittag-Leffler data with tail parameter $\beta=0.8$ and scale $\sigma=1$, for a sample size of $n=200$ (left) and $n=1000$ (right). The dark lines are the means and the red dotted lines show the true tail
parameter. To deduce the correct tail parameter estimates from one of those Hill plots is virtually impossible. To estimate the tail parameter of a Mittag-Leffler distribution with the Hill estimator, the sample size has to be much larger and one has to choose a small tuning parameter $r$. In case that only events above a high threshold are recorded, $n=10000$ events are extremely unrealistic. There is a vast literature on bias-reduced versions of the Hill estimator and on the optimal choice of $r$, mainly based on imposed second-order regular variation conditions [see e.g. @beirlantBook, Ch.4.4 and 4.7 and references in it]. Also, there are hundreds other tail-index estimators not considered in this article, since this would go beyond the scope of our article. For example the moment estimator [@dekkers1989moment], the Pickands estimator [@pickands1975statistical], the QQ-estimator [@Kratz96], to name a few. A nice overview can be found in [@fedotenkov2018review]. However, we know from the Theorem in Section \ref{sec:scaling} that the inter-exceedance times are asymptotically Mittag-Leffler distributed, and hence it is unsurprising that general tail (and scale) estimation methods that do not take into account this structure are statistically less efficient [@kozubowski2001] on the *thresholded* data. Finally, the Hill estimator completely fails in the important special case where the inter-arrival times are exponentially distributed and not heavy-tailed. For these reasons, we propose to use the log-Moment estimator or the MLE for Mittag-Leffler distributions.

```{r Hillplots,  fig.height=5, fig.width=4, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{fig:Hillplots} Hill plots for m=100 simulated Mittag-Leffler datasets with true tail 0.8 and sample size 200 (first panel) and 10000 (second panel), with number of upper order statistics r on which the Hill estimator is based on the x-axis. The grey thin lines are the Hill plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter. ", out.width = '50%'}

hill_estim<-function(k,data){
  n<-length(data)
  data<-sort(data)
  data_thinned<-data[(n-k):n]
  r<-1/k * sum(log(data_thinned/data_thinned[1]))
  return(1/r)
}


hill_estim_range<-function(k_min,data,k_max=n,true_tail){
  n<-length(data)
  x_values<-k_min:k_max
  y_values<-sapply(x_values,hill_estim,data=data)
  df<-data.frame(x=x_values,y=y_values)
  return(df)
}


hill_plot_values<-data.frame(x=numeric(),y=numeric(),rep=numeric())
for  (m in 1:100){
data_ml_1<-rml(n=200,tail=0.8,scale=1)
df<-hill_estim_range(k_min=30,data=data_ml_1,true_tail=0.8)
df<-df %>% mutate(rep=m)
hill_plot_values<-bind_rows(df,hill_plot_values)
}

mean_n200<-hill_plot_values %>% group_by(x) %>% summarize(mean=mean(y))
p1<-hill_plot_values %>% ggplot() + geom_line(aes(x=x,y=y,group=rep), alpha=0.1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=x, y=mean),colour="black",data=mean_n200) + 
  ylab("Estimated tail") +
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+
  xlab("Order Statistics")+
  ylab("Hill-Estimator of Tail Index")


hill_plot_values<-data.frame(x=numeric(),y=numeric(),rep=numeric())
for  (m in 1:100){
  data_ml_2<-rml(n=10000,tail=0.8,scale=1)
  df<-hill_estim_range(k_min=30,k_max=200,data=data_ml_2,true_tail=0.8)
  df<-df %>% mutate(rep=m)
  hill_plot_values<-bind_rows(df,hill_plot_values)
}
mean_n1000<-hill_plot_values %>% group_by(x) %>% summarize(mean=mean(y))

p2<-hill_plot_values %>% ggplot() + geom_line(aes(x=x,y=y,group=rep), alpha=0.1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=x, y=mean),colour="black",data=mean_n1000) + 
  ylab("Estimated tail") +
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+
  xlab("Order Statistics")+
  ylab("Hill-Estimator of Tail Index")
 


grid.arrange(p1,p2,nrow=2,top="Hill plots") 
```

Since the exponential distribution is nested in the Mittag-Leffler family of 
distributions, a Likelihood-ratio Test (LRT) seems to be an appropriate way to choose 
between a model with exponential and Mittag-Leffler inter-exceedance times.
Although the two models are nested, the asymptotic distribution is not 
$\chi^2_1$-distributed, and Wilk's Theorem does not hold: under $H_0$, the 
parameter $\beta$ of Mittag-Leffler distribution is equal to $1$, and hence lies
on the boundary of the parameter space $(0,1]$. 
Instead, a valid approach is a bootstrapped Likelihood-ratio test [see e.g. @davison1997bootstrap]. 
Figure \ref{Fig:LRT} displays the (simulated) power for the bootstrapped LRT for Mittag-Leffler distributions with varying tail parameters based on 1000 simulation runs. As expected, the power decreases for tail parameters close to one, since the Mittag-Leffler distribution converges as $\beta \uparrow 1$ to an exponential distribution; it becomes hard to differentiate a Mittag-Leffler distribution from an exponential. 

```{r LRT_power, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{Fig:LRT} Power for bootstrapped LRT for different sample sizes, varying tails and scale parameter equal to 1.", out.width='90%'}
load(here::here("article_springer","article_springer_files","ML_LRT_simu","estimates_df_LRT_boot1_01.RData"))
df_LRT_boot_01 %>%  ungroup() %>% filter(n=="20" | n=="50" | n=="100" | n=="200") %>% ggplot(aes(x=true.tail,y=power)) +  geom_line(aes(y=power,group=factor(n),color=factor(n),linetype=factor(n)),size=0.5)+
  scale_linetype_manual(values = c("solid","dashed","twodash","dotted"),name  ="Sample size")+
   labs(y="Power",x= "True tail parameter")+
  scale_color_manual(values=c("red", "blue","darkgreen","black"), name  ="Sample size") +
  ggtitle("Power of Likelihood-Ratio Test")+
   theme(plot.title = element_text(hjust = 0.5))
```


# Inference on Exceedance times

The Theorem in Section \ref{sec:scaling} implies that for a high 
threshold $\ell$ we may approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p_{\ell}))$ distribution, 
where the function $b(c)$ varies regularly at $\infty$ with parameter $1/\beta$.
Building on the POT (Peaks-Over-Threshold) method, we propose the following estimation procedure for the distribution of inter-exceedance time $T(\ell)$: 

1. Extract the $K$ largest order statistics 
(i.e. the $K$ largest values, where e.g. $K = 300$) 
$X_{(1)}, \ldots, X_{(K)}$ together with their timestamps $T_{(1)}, \ldots, T_{(K-1)}$. 

2. Choose a minimum number of exceedances $K_0\leq K$, e.g. $K_0 = 5$, and for each $k$ ranging from $K_0$ to $K$: 
    a) extract the set $\mathcal T_k$ of exceedance times between the magnitudes exceeding the threshold $X_{(k)}$
    b) fit a Mittag-Leffler distribution to $\mathcal T_k$, resulting in the parameter
    estimates $\hat\beta_k$ and $\hat \sigma_k$.
  
3. Plot $k$ vs.\ $\hat \beta_k$. To the right ($k \uparrow K$, low threshold), the asymptotics are off and bias is high. To the left ($k \downarrow K_0$, high threshold), data is scarce and variance is high. In the middle, look for a region of *stability* for a parameter estimate $\hat \beta$. Choose as $\hat \beta$ a representative value from this region.

4. Plot $k$ vs.\ $k^{1/\hat \beta} \hat \sigma_k$. Again, choose a region of *stability* and a representative $\hat \sigma_0$ from that region.

The inferred values $\hat \beta$ and $\hat \sigma_0$ can then be interpreted as follows: 
Setting the threshold at $X_{(k)}$, the threshold exceedance times follow a 
Mittag-Leffler distribution with shape parameter $\hat \beta$ and scale parameter
$\hat \sigma_0 k^{-1/\beta}$. 

To clarify Step 4: Recall that by the theorem, $\sigma_k / b(1/p_{\ell})$ is expected to stabilize 
around a constant as $k$ gets smaller. Since $b$ is regularly varying with parameter
$1/\beta$, we have $b(1/p_{\ell}) = p_{\ell}^{-1/\beta} / L(1/p_{\ell})$ for some slowly varying function $L$. 
Approximating $p_{\ell}$ by $\hat p_{\ell} := k / n$, we have 
$$\text{const} \approx \sigma_k / b(1/p_{\ell}) = \sigma_k \times p_{\ell}^{1/\beta} L(1/p_{\ell}) \approx \sigma_k \times k^{1/\beta} n^{-1/\beta} L(n/k)$$
Assuming that the variation of $L(n/k)$ is minor, we can hence see that 
$\sigma_k k^{1/\beta}$ stabilizes.

**Remark**:

: We approximated $p_{\ell}$, the probability that an event is larger than $l$, by its relative frequency. One could also approximate this tail probability by the GPD distribution fitted to the exceedances.   

For computationally efficient estimates of the Mittag-Leffler parameters we have used 
the method of log-transformed moments. This estimation method provides 
point estimates as well as confidence intervals based on sampling variance [@Cahoy2013], 
and has been implemented in the R software package
`MittagLeffleR` [@MittagLeffleR]. The stability plots for $\hat \beta$ and $\hat \sigma_0$
can be furnished with these confidence intervals, see e.g.\ Figure \ref{fig:flares}, 
to produce (non-simultaneous) confidence bands. 
These stability plots were produced with the R package `CTRE` [@CTRE]. 
We have verified the validity of our estimation algorithm  via simulations, 
see Section \ref{Simulationstudy}. 


# Simulation Study {#Simulationstudy} 

To test our inference method via stability plots, we have simulated $m=100$ datasets with $n=10000$ independent waiting time and magnitude pairs $(W_k, J_k)$ for waiting times that follow


(i) a stable distribution,  


(ii) a Pareto distribution and


(iii) an exponential distribution.   



The magnitudes are in all scenarios standard Gumbel distributed. In order to have exact analytical values available for $\beta$ and $\sigma_0$, a distribution for $W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:stability} is known. 

**Case (i):** For (i) we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{eq:stability}, then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation [see e.g. the vignette on parametrisation in @MittagLeffleR]
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. By the Theorem, the distribution of $T(\ell)$ is approximately 
$$
{\rm ML}(\beta, p_{\ell}^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta}),
$$
which means 
$\sigma_0 = n^{1/\beta}$. 

**Case (ii):** In the Pareto example we choose $P(W>t)=Ct^{-\beta}$ with $C=(1/\Gamma(1-\beta))^{1/\beta}$. We have chosen $\beta=0.8$ in both cases (i) and (ii). 

**Case (iii):** We choose exponentially distributed waiting times with a rate 
parameter of $1$.

Figure \ref{Fig:TailSimu} shows the graphical "stability plots" for the 
estimation of the tail parameter, where 

+ rows correspond to cases (i), (ii) and (iii), and
+ columns correspond to estimators (log-Moment estimator, Maximum-Likelihood). 

We plot the tail parameter estimates $\hat \beta(k)$ against $k$ 
for each of the $m=100$ simulation runs. 
Thin grey lines represent individual simulation runs, 
and the thicker black line is their mean. 
Recall that $k$ is the index of the order statistics of $J_k$ at which the 
threshold $\ell$ is placed. 
<!-- Note that the Hill estimator is based on the waiting times, not on the  -->
<!-- inter-exceedance times, meaning that the estimation is based on more data.  -->
<!-- If one were to base the Hill-estimation only on the inter-exceedance times,  -->
<!-- the sample size would be too small and it would be impossible to deduce an  -->
<!-- estimate for the tail parameter from the plots (compare Figure \ref{fig:Hillplots}).  -->

<!-- In the right-hand Hill-estimator column, the $k$ on the $x$-axis corresponds to -->
<!-- $r$ from \eqref{eq:Hill}. -->
<!-- The Hill estimator appears to be nicely unbiased on Pareto data, -->
<!-- but compared to the other two estimators, it has a higher variance,  -->
<!-- as can be seen from the wider spread of the simulated curves.  -->
<!-- This high variance means that that a single estimate is less reliable compared -->
<!-- to the other two estimators.  -->
<!-- This effect is amplified if one only has a thresholded, and thus smaller dataset -->
<!-- available, to the extent that the Hill estimates become severely flawed -->
<!-- (see Section \ref{sec:ML}).  -->

The performance of log-Moment and Maximum-Likelihood estimators for the tail resp. the scale parameter is shown in Figure \ref{Fig:TailSimu} resp. \ref{Fig:ScaleSimu}. Both estimators show good performance, with a slight advantage for the Maximum-Likelihood estimator. This advantage is paid for with a higher computational cost. Moreover, the bottom row in Figure \ref{Fig:TailSimu} shows clearly that the log-Moment and Maximum-Likelihood estimators generalize to the exponential case ($\beta = 1$) whereas the Hill-estimator would not.  
Notice that any data below a certain threshold gets discarded in our approach and hence need not to satisfy the iid assumption. In our simulation study we only simulated data from iid sequences of $(W_k)_{k \in \mathbb{N}}$, in real data situations its likely that there are dependencies or more complex data generating processes vanishing for higher thresholds. We only need the exceedances as well as the inter-exceedance times to be iid. 
 
<!-- Since there is no Hill-estimate of a scale parameter, there are only two columns.  -->


```{r TailSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:TailSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponentially distributed waiting times (lower row). Left column: log-Moment estimator, right column: MLE. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter.", fig.show='hold', out.width = '100%'}

path <-
  here::here("article_springer",
             "article_springer_files",
             "Simulation_results")
files <- list.files(path)
file_dirs <- paste(path, "/", files, sep = "")
invisible(sapply(
  file_dirs,
  FUN = load,
  envir = .GlobalEnv,
  verbose = FALSE
))

#Tail Parameter

# Example One

#logMoment estimator
logMom_Ex1_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_tail08_logMoms_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_logMoms_Ex1) + 
  ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex1_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_tail08_mles_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex1) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#Hill estimator
# hill_Ex1_tail <-
#   ggplot() + geom_line(data = tbl_estimates_tail08_hill_Ex1,
#                        aes(x = k, y = value, group = rep),
#                        alpha = 0.05) +
#   coord_cartesian(ylim = c(0.5, 1.5)) +
#   geom_line(data=means.tbl_hill_Ex1,aes(x=k, y=mw),colour="black") + 
#   ylab("Estimated tail") +
#   geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")


#Example Two

#logMoment estimator
logMom_Ex2_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_Ex2_Pareto_tail08_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_logMoms_Ex2) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex2_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_Ex2_Pareto_tail08_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_mles_Ex2) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

# #Hill estimator
# hill_Ex2_tail <-
#   ggplot() + geom_line(aes(x = k, y = value, group = rep),
#                        alpha = 0.05,
#                        data = tbl_estimates_Ex2_Pareto_tail08_hill_times) +
#   coord_cartesian(ylim = c(0.5, 1.5)) +
#   geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_hill_times_Ex2) + 
#   ylab("Estimated tail") +
#   geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")

#Example Three

#logMoment estimator
logMom_Ex3_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_Example3_Exp_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_logMoms_Ex3) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#ml estimator
mle_Ex3_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_estimates_Example3_Exp_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex3) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

# #Hill estimator
# hill_Ex3_tail <-
#   ggplot() + geom_line(aes(x = k, y = value, group = rep),
#                        alpha = 0.05,
#                        data = tbl_estimates_Example3_Exp_hill_times) +
#   coord_cartesian(ylim = c(0.5, 10)) +
#   geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_hill_times_Ex3) + 
#   ylab("Estimated tail") + 
#   geom_hline(yintercept=1, linetype="dashed", color = "red")+ xlab("r")
# 
grid.arrange(
  arrangeGrob(logMom_Ex1_tail,logMom_Ex2_tail,logMom_Ex3_tail,top="log-Moment"),
  arrangeGrob(mle_Ex1_tail, mle_Ex2_tail, mle_Ex3_tail,top="MLE"),
  # arrangeGrob(hill_Ex1_tail,hill_Ex2_tail,hill_Ex3_tail,top="Hill"),
  ncol=2, top="Stability plots: tail parameter"
)
```


```{r ScaleSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:ScaleSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponentially distributed waiting times (lower row). Left column: log-Moment estimator, right column: MLE. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true scale parameter.", fig.show='hold', out.width = '100%'}
#Scale Parameter

#Example One
logMom_Ex1_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_logMoms_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x = k, y = mw), colour = "black", means.tbl_scales_logMoms_Ex1) + 
  ylab("Estimated scale") +
  geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex1_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_mles_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex1) + 
  ylab("Estimated scale") +
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Two

logMom_Ex2_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_logMoms_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex2) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex2_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_mles_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex2) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Three

logMom_Ex3_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_logMoms_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex3) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red") 

mle_Ex3_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       alpha = 0.05,
                       data = tbl_scales_mles_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex3) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

grid.arrange(
  arrangeGrob(logMom_Ex1_scale,logMom_Ex2_scale,logMom_Ex3_scale,top="log-Mom"),
  arrangeGrob(mle_Ex1_scale,mle_Ex2_scale,mle_Ex3_scale,top="MLE"),
  ncol = 2, top="Stability plots: scale parameter"
)
```

# Data example

We now want to apply the proposed method to a real data example, the solar flare data which was already mentioned in Section 1 and can be seen in Figure \ref{fig:thresholdedBursty}. The data were extracted from the "complete Hard X Ray Burst Spectrometer event list", a comprehensive reference for all measurements of the Hard X Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,772 events were detected, with the "vast  majority being solar flares". To assure stationarity and due to missing values during the years 1983 and 1984, we based our analysis just on the year 1982, in which 2,488 events happened. The list includes the start time, peak time, duration, and peak rate of each event. We have used "start time" as the variable for event times, and "peak rate" as the variable for event magnitudes. 
 
Before we apply the approach described in Section 5 to the solar flare data, we first have to check if all model assumptions are fulfilled. The CTRE model is based on three main assumptions, which are repeated below. For each assumption, we suggest one means of checking if it holds: 

i.i.d.:

: After removing the "noise observations" below the smallest threshold 
  $\ell_0$, the pair sequence $(T(\ell_0, i), X(\ell_0,i))$ is i.i.d. 
  An indication if this is true is given by an auto-correlation plot. Since we are expecting the inter-exceedance times to be Mittag-Leffler distributed and hence to have infinite mean but finite log-moments, we first take the logarithms of the times.
  

Uncoupled:

: Each $T(\ell, i)$ is independent of each $X(\ell, i)$. We propose an empirical copula
  plot to check for any dependence. 
  
  

${\rm ML}(\beta, \sigma)$ distribution of $T(\ell, i)$:

: Apply a cutoff at the lowest threshold $\ell_0$, 
  extract the threshold crossing times, 
  and create a QQ Plot for the Mittag-Leffler distribution. 
  Use a Log-moment estimate of the tail parameter for the theoretical / population 
  quantiles of the plot.

**Remark:**

: The ACF plots of course can just give an indication whether there are dependencies, since they actually just measure linear dependencies. Furthermore, if one calculates the ACF for the logarithmic inter-exceedance times, the ACF indicates on the original scale a multiplicative dependence.  

Figures \ref{fig:flare-diagnostics-1}, \ref{fig:flare-diagnostics-2} and \ref{fig:flare-diagnostics-3} show the diagnostic plots for a minimum threshold chosen at the 100th order statistic. There is some residual autocorrelation for the sequence of threshold exceedance times that is not accounted for by the CTRE model.  

```{r flare-diagnostics-1, fig.height=7, fig.cap="\\label{fig:flare-diagnostics-1} Diagnostic plots for the solar flare data based on the 100 upper order statistics: auto-correlation and cross-correalation function."}
flares_ctre <- flares %>% ctre() %>% thin(k = 100)
log_interarrivals_flares<-log(interarrival(flares_ctre))
exceedances_flares<-log(magnitudes(flares_ctre))
acf1<-ggAcf(log_interarrivals_flares)+ggtitle("ACF-plot of log(T(l))")+theme(plot.title = element_text(hjust=0.5))
acf2<-ggAcf(exceedances_flares)+ggtitle("ACF-plot of X(l)")+theme(plot.title = element_text(hjust=0.5))
ccf1<-ggCcf(log_interarrivals_flares,exceedances_flares)+ggtitle("CCF-plot of log(T(l)) & X(l)")+theme(plot.title = element_text(hjust=0.5))
ccf2<-ggCcf(exceedances_flares,log_interarrivals_flares)+ggtitle("CCF-plot of X(l) & log(T(l))")+theme(plot.title = element_text(hjust=0.5))
grid.arrange(acf1,acf2,ccf1,ccf2,ncol=2)
```


```{r flare-diagnostics-2, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-2} Diagnostic plots for the solar flare data: empirical copula.",out.width="70%"}
empcopula(flares_ctre) + ggtitle("Empirical Copula: T(l) vs. X(l)")+theme(plot.title = element_text(hjust=0.5))
```

```{r flare-diagnostics-3, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-3} Diagnostic plots for the solar flare data: QQ Plot.",out.width="70%"}
sample_data <- flares_ctre %>% interarrival()
n <- length(sample_data)

population_data <- MittagLeffleR::qml(p = stats::ppoints(n), tail = tail, 
  scale = 1)

extRemes::qqplot(x = log(sample_data), y = log(population_data), 
                 main = "QQ-plot: Exceed. Times vs Mittag-Leffler",font.main = 1,
                 xlab = "log Exceedance Times", 
                 ylab = "log Mittag-Leffler") 
```

Figure \ref{fig:flares} shows the stability plots for the solar flare data, on the left for the tail parameter and on the right for the scale parameter. The dark grey ranges correspond to 95% confidence intervals, which are derived from the asymptotic normality of the Log-moment estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR]; dashed lines show the deduced true values of $\beta$ resp.\ $\sigma_0$. The stability plot for the tail stabilizes nicely around 0.9 (dashed line), while 
the scale parameter stabilizes less obviously near $3 \times 10^7$ (dashed line).
The growth of the scale parameter for lower threshold appears to be closer to linear in $p_{\ell}$, 
rather than proportional to $p_{\ell}^{1/0.9}$ as suggested by the Mittag-Leffler
fits. The reason for this is likely that the overall goodness of fit as 
compared to an exponential distribution is improved due to the peaked shape of the Mittag-Leffler distribution near $0$,
rather than its tail behaviour at $\infty$.
The reported fit should hence come with the caveat that a Mittag-Leffler 
distribution models exceedance times well only up to certain time-scales. 
More research is needed into the modelling of scale transitions, where
inter-exceedance times appear to have different power laws across different 
time scales.


```{r solar-flare-tail-scale, message=FALSE, fig.height=4.5, fig.width=8, fig.cap="\\label{fig:flares} Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset. Dotted horizontal lines are at $\\beta = 0.9$ and $\\sigma_0 = 3 \\times 10^7$ seconds $\\approx 0.95$ years."}
thin_flares_ctre <- flares %>% ctre() %>% thin(k = 700)
par(mfrow=c(1,2)) 
MLestimates(thin_flares_ctre, tail = 0.9, scale = 3 * 1E7) 
```

The fit with a Mittag-Leffler distribution ($\beta = 0.9$) seems to be good (see Figure \ref{fig:flare-diagnostics-3}), though there are signs that the power-law tail tapers off for very large inter-threshold crossing times. There is no apparent dependence between threshold exceedance times and event magnitudes seen in the copula plot (see Figure \ref{fig:flare-diagnostics-2}). We also conduct a bootstrapped LRT for the null hypothesis of exponentially distributed inter-arrival times and received a $p$-value of $p<0.01$. 

# Predicting the time of the next threshold crossing

According to Figure \ref{fig:flares}, for a threshold $\ell$ at the $k$-th order 
statistic, the estimated threshold exceedance time distribution is approximately
$$
T(\ell) \sim {\rm ML}(\hat{\beta}, k^{-1/\hat{\beta}} \hat{\sigma}_0), 
$$
where $\hat{\beta} = 0.9$ and $\hat{\sigma}_0 = 3.0 \times 10^7 {\rm sec}$. 
Unlike the exponential distribution, the Mittag-Leffler distribution is not memoryless, and the probability density of the time $t$ until the next threshold crossing will depend on the time $t_0$ elapsed since the last threshold crossing.
This density is approximately equal to 
$$
p(t|\beta, \sigma_0, \ell, t_0) = \frac{f(t + t_0 | \beta, k^{-1/\beta} \sigma_0)}{\mathbf P[T_\ell > t_0]}
$$
where $f(\,\cdot\, | \beta, k^{-1/\beta} \sigma_0)$ is the probability density of ${\rm ML}(\beta, k^{-1/\beta} \sigma_0)$. 
The more time has passed without a threshold crossing, the more the probability distribution shifts towards larger values for the next crossing
(see Figure \ref{fig:hazard}, left panel). The hazard rate 
$$
h(t) = \frac{f(t| \beta, k^{-1/\beta} \sigma_0))}{\int_t^\infty f(\tau| \beta, k^{-1/\beta} \sigma_0))\,d\tau}
$$
approximates the risk of a threshold crossing per unit time, and is a decreasing function for the Mittag-Leffler distribution. 
```{r hazard, fig.height=4, fig.cap="\\label{fig:hazard} Left: Conditional distribution of time until next threshold crossing, depending on elapsed time $t_0$ since last crossing ($\\beta = 0.9$, $\\sigma_0 = 1$). Right: Hazard rate depending on tail parameter $\\beta$."}
tail <- 0.9
scale <- 1
t_0 <- c(0, 1, 10)
from <- 0.1
to <- 100 * scale
xx <- exp(seq(from = log(from), to = log(to), length.out = 100))
par(mfrow = c(1,2))
df1<-data.frame(x=xx,y=rep(1, length(xx)))
col<-c("red","blue","darkgreen","black")

plot(xx, rep(1, length(xx)), ylim = c(0.001,1), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'p', main = "Next Threshold Crossing Time",font.main = 1)
for (k in 1:length(t_0)) {
  cond <- pml(q = t_0[k], tail = tail, scale = scale, lower.tail = FALSE)
  yy <- dml(x = xx + t_0[k], tail = tail, scale = scale) / cond
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("t_0 = 0", "t_0 = 1", "t_0 = 10"), col = c("red","blue","darkgreen"), lty = 2:4)

betas <- c(0.7, 0.8, 0.9, 0.99)
t_0 <- 1

plot(xx, rep(1, length(xx)), ylim = c(0.001,2), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'h', main = "Mittag-Leffler Hazard Rate",font.main = 1)
for (k in 1:length(betas)) {
  yy <- dml(x = xx, tail = betas[k], scale = scale) / pml(
    q = xx,
    tail = betas[k],
    scale = scale,
    lower.tail = FALSE
  )
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("beta = 0.7", "beta = 0.8", "beta = 0.9", "beta = 0.99"), col = c("red","blue","darkgreen","black"), lty = 2:5)

```
The closer $\beta$ is to $1$, the more the hazard rate mimics that of an 
exponential distribution (a constant function, see Figure \ref{fig:hazard}, 
right panel). 


# Discussion & Conclusion

We have applied the POT (Peaks-over-Threshold) model, a mainstay of extreme value theory, to "bursty" time series, which have been studied 
intensively in statistical physics. Burstiness is characterized by power-law waiting times between events, and we have shown that the Mittag-Leffler distribution arises naturally as a scaling limit for the inter-exceedance times of high thresholds. Moreover, we have derived the following non-linear scaling behaviour: $\sigma \sim p_{\ell}^{-1/\beta}$, where $\sigma$ is the scale parameter of the distribution of threshold 
exceedance times, $p_{\ell}$ is the fraction of magnitudes above the threshold $\ell$, and $\beta$ the exponent of the power law. 
This "anomalous" scaling behaviour in the bursty setting entails two phenomena: 

i) a heavy tail of the inter-arrival time distribution of threshold crossings (long rests), and 

ii) a high propensity for more threshold crossing events immediately after each threshold crossing event (bursts). 

The Mittag-Leffler distribution captures both phenomena, due to its heavy tail as well as its stretched exponential (peaked) asymptotics for small times. It generalizes the exponential distribution, and in the solar flare data example, this generalization is warranted, because the likelihood-ratio test is strongly significant. 

When we introduced the CTRE model, we assumed that all events are i.i.d. This assumption is likely sufficient but not necessary for our limit theorem to hold. Moreover, any data below a (minimum) threshold $\ell_0$ is discarded for CTREs, and hence need not satisfy the i.i.d. assumption. For the purposes of statistical inference, we merely require that the inter-threshold-crossing times are i.i.d. 

The CTRE approach to model "non-Poissonian" threshold crossing times should be contrasted with the well-documented approach of clusters of extremes, see e.g. @ferro2003inference. When the underlying stochastic process is *stationary*, the exceedances of high thresholds form, asymptotically, a *Cluster Poisson Process*.
In the setting of this article, however, clustering-like dynamics occur due to the *non-stationarity* of the underlying renewal-reward process, which has infinite-mean renewal times. 
Hence CTRE and Cluster Poisson Process shouldn't be viewed as competing methods, as the underlying data generating processes are quite different. To differentiate between the two models we use the term *bursty* which is standard in the context of heavy-tailed inter-arrival times in the physics community [e.g. @Barabasi2005;@Vasquez2006;@Karsai2012;@Vajna2013]). In weighing the evidence for either of the two data generating processes, criteria could be developed, based e.g. on measures of surprise [@Lee15], which may prove to be valuable for future applied statisticians.

Finally, we note that assuming a purely scale-free pattern for event times may be too rigid an 
assumption, which unnecessarily limits the applicability of CTREs. Often, the heavy-tailed character of the inter-arrival time
distribution holds at short to intermediate time scales, and is truncated (or tempered, 
reverting to an exponential distribution) at very long time scales [see e.g. @MeerschaertRoyQin; and @Aban06]. In such situations, a "tempered" Mittag-Leffler distribution may provide a better fit, which we aim to introduce in follow-up work. 


# Acknowledgements {-}

The authors would like to thank Prof. Peter Scheffler for insights on stochastic process limits for CTRMs, Prof. Roland Fried for discussion regarding the statistical methods and Gurtek Gill who helped create the MittagLeffleR R-package. 


\newpage

# References {-}

