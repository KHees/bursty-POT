---
title: "Statistical Inference for inter-arrival times of extreme events in bursty time series"
# titlerunning: "CTRE: POT for Bursty Time Series"
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
author: 

- name: "Katharina Hees"
  affiliation: a
  email: "hees@statistik.tu-dortmund.de"
  
- name: "Smarak Nayak"
  affiliation: b
  email: "smarak.nayak@nab.com.au"
  
- name: "Peter Straka"
  affiliation: c
  email: "straka.ps@gmail.com"
  
address:

- code: a
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

- code: b
  address: "National Australia Bank, Melbourne, Australia"
    
- code: c
  address: "School of Mathematics and Statistics, UNSW, Sydney, Australia"
    
corrauth:
  name: "Katharina Hees"
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed distribution. The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  This article proposes a new model for the _inter-exceedance times_ of events 
  above high thresholds; the threshold exceedances itself are modeled via the standard 
  Peaks-Over-Threshold (POT) method. For high thresholds and 
  infinite-mean waiting times, we show that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process of threshold
  exceedances.
  We provide graphical means of estimating model parameters and assessing 
  model fit. Along the way, we apply our inference method to a real-world
  bursty time series, and 
  show how the memory of the Mittag-Leffler distribution affects 
  the predictive distribution for the time until the next extreme event. 

bibliography: CTRMstats.bib
csl: elsevier-harvard.csl
output: 
  rticles::elsevier_article:
    number_sections: true
    fig_caption: yes

                

params:
  tail: 0.8
  n: 10000

header-icludes: \usepackage{amssymb,natbib}


---

```{r get-rticles, eval=FALSE, include=FALSE, cache=TRUE}
# use this rticles version: 
devtools::install_github("rstudio/rticles")
# use the newest MittagLeffleR version:
devtools::install_github("strakaps/MittagLeffleR")
library(MittagLeffleR)
devtools::install_github("strakaps/CTRE")
library("CTRE")
library(CTRE)
install.packages("here")
library(here)
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRE)
library(MittagLeffleR)
library(magrittr)
library(gridExtra)
library(ggplot2)
library(dplyr)
set.seed(12345)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour in terms of the occurrence of events have received strong interest in the recent statistical physics literature [@Barabasi2005;@Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; @Min2010; @Karsai2011;@Bagrow2013]. They have been observed in the context of earthquakes, sunspots, neuronal activity and human communication [see @Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point process by @hawkes1971point), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
The Peaks-Over-Threshold model [POT, see e.g. @ColesBook] applies a
threshold to the magnitudes, and fits a Generalized Pareto distribution 
to the threshold exceedances. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@Hsing88]. 
Then as one increases the threshold and thus decreases the threshold 
crossing probability $p_{\ell}$, the Poisson process is rarefied, i.e. its 
intensity decreases _linearly_ with $p_{\ell}$ [see e.g. @beirlantBook]. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size increases and the threshold crossing
probability $p_{\ell}$ decreases, the fractional Poisson process is rarefied: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @hees2016joint; @hees2017coupled], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Section 3.
We give a statistical procedure to estimate model parameters via stability plots 
in Section 5, but to set the stage we first discuss inference for the 
Mittag-Leffler distribution in Section 4. A simulation study of the effectiveness of our statistical procedure is given in Section 6. In Section 7 we apply our method to a real data set.  In Section 8, we discuss the memory property of the  Mittag-Leffler distribution, and how it affects the predictive distribution for the time until the next threshold crossing event. Finally we close with a discussion and conclusion in Section 9.
For all statistical computations we have used R [@R]. 
All code and data used for the analysis in this article has been organized into 
an R package `CTRE` (<https://github.com/strakaps/CTRE>).
The source code for the figures generated in this manuscript is 
available online at <https://github.com/strakaps/bursty-POT>. 


# Continuous Time Random Exceedances (CTRE)

As a model for extreme observations, we use a Marked Renewal Process (MRP):

**Definition (MRP):** 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random variables, where the $W_k > 0$ are interpreted as the *waiting times* 
and $J_k \in \mathbb{R}$ as the *event magnitudes*. If $W$ and $J$ are independent, the Marked Renewal Process is said to be *uncoupled*. 


In the following we denote with $x_L \in [-\infty, +\infty)$ and $x_R \in (-\infty, +\infty]$) the left and right endpoint of the distribution of $J$. We assume that the $k$-th magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on an MRP, we define the Continuous Time Random Exceedance model
(CTRE) as follows:

**Definition (CTRE):** 

: Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
Define the pair of random variables $(X(\ell), T(\ell))$ via 
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k.$$
By restarting the MRP at $\tau(\ell)$, inductively define the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$, 
called the "inter-arrival times" and the "exceedances", respectively.
The pair sequence $(X(\ell, n), T(\ell, n))_{n \in \mathbb N}$ is called 
a Continuous Time Random Exceedance model (CTRE). 
If the underlying MRP is uncoupled, then the CTRE is also called 
uncoupled. 


```{r thresholdedBursty, message=FALSE, fig.height=6, fig.width=7,out.width='70%',fig.align='center',fig.cap="\\label{fig:thresholdedBursty} Exceedances (red) and times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line). Upper picture: Simulated data with stable distributed waiting times. Lower picture: Solar flares during 1982."}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctre <- ctre(data.frame(times, magnitudes)) 
p1<-plot(sim_ctre, p = 0.01, main = "Simulated MRP") + 
  ggtitle("Simulated MRP")
p2<-flares %>% ctre() %>% plot(p = 0.02, log = 'y', main = "HXRBS data") +
  ggtitle("HXRBS data")
grid.arrange(p1,p2)
```

In this article, we restrict ourselves to the uncoupled case, where $W$ and $J$ are independent. Then the two sequences $X(\ell, n)_{n \in \mathbb N}$ and $T(\ell, n)_{n \in \mathbb N}$ are independent as well. To see why, note that $X(\ell)$ is, in distribution, simply equal to $J - \ell | J > \ell$, independent of any waiting time $W_k$.  
We assume for the rest of the article, that the magnitudes $(J_i)_{i \in \mathbb{N}}$ belong to the the max-domain of attraction of some non-degenerate distribution. This means there exist $a_n>0$ and $d_n \in \mathbb{R}$ such that 
$$ a_n^{-1}(J_1 \vee \ldots \vee J_n -d_n) \Rightarrow A \text{ as } n \rightarrow \infty.$$
Hence, the distribution of $A$ is a generalized extreme value distribution (GEV) which distribution function is given by 
$$ F(x;\xi) = \begin{cases}\exp(-(1+\xi x)^{-1/\xi}) & \xi\neq0 \\ \exp(-\exp(-x)) & \xi = 0\end{cases}.$$ 
The GEV is subdivided into the Gumbel ($\xi=0$), the Weibull ($\xi<0$) and the Fr'echet ($\xi>0$) family of distributions.  

Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top panel, where $W$ has a stable distribution with tail parameter $\beta =$ `r params$tail` (and skewness $1$ and location $0$), and where $J$ is from a standard Gumbel distribution. In the bottom panel, we plot a time series of solar flare intensities derived from a NASA dataset [@HXRBS] which we will later examine more closely (see Section 7). Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear continuously. The threshold exceedances, however, appear to have visually similar statistical behaviour in both models. Observations below a threshold are commonly discarded in Extreme Value Theory (POT approach); likewise, the CTRE model interprets these observations as noise and discards them.

# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state and prove the key theorem. For an accessible introduction to regular variation and stable limit theorems, we recommend the book by @MeerschaertSikorskii.

**Theorem:** 

: Let the waiting times $W_k$ be in the domain of attraction of a positively skewed sum-stable law with stability parameter $0 < \beta < 1$; more precisely,
\begin{align} \label{eq:stability}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
for a function $b(n)$ which is regularly varying at $\infty$ with parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$. Write $p_{\ell} := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p_{\ell})} \to Z_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$
holds, where the Mittag-Leffler random variable $Z_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sZ_\beta)] = \frac{1}{1+s^\beta}.
$$ 


*Proof of Theorem:* We interpret the threshold crossing time $T(\ell)$ as the hitting time of the 
underlying CTRM (Continuous Time Random Maxima) or "max-renewal process", 
and then utilize a result by @MeerschaertStoev08. 
The running maximum process is defined as 
$$
M(c) := J_1 \vee \ldots \vee J_{\lfloor c \rfloor},
$$
and since we assume that the $J_k$ have a continuous distribution, there exist 
norming functions $a(c)$ and $d(c)$ such that 
$$
\mathbf P\left[ \frac{M(c) - d(c)}{a(c)} \le \ell^* \right] 
\longrightarrow F(\ell^*), \quad c \to \infty
$$
where $F$ is a generalized extreme value distribution, and $\ell^*$ is any 
value from the support of $F$. 
The CTRM process is then defined via 
$$
V(t) = M(N(t)), \quad t \ge 0
$$
where $N(t)$ is the renewal process associated with the waiting times 
$W_k$: 
$$
N(t) = \max\{n: W_1 + \ldots + W_n \le t\}.
$$
Now a key observation is that
$$
T(\ell) = \inf\{t: V(t) > \ell\}, 
$$
and that 

\begin{align}
T(\ell) > t \quad \text{ if and only if } \quad V(t) \le \ell. \label{inverserelat}
\end{align}

By [Theorem 3.1, @MeerschaertStoev08], we have the stochastic process 
convergence 

\begin{align}
\frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\stackrel{d}{\longrightarrow} Y(t),  \quad c \to \infty, \label{TheoMS}
\end{align}

for $t > 0$, where $Y(t)$ is a time-changed ("subordinated") extremal process, and where 
$\tilde b(c)$ is a regularly varying norming function which is
_inverse_ to $b(c)$, in the sense that 
$b(\tilde b(c)) \sim c \sim \tilde b(b(c))$ [@BinghamGoldieTeugels]. 

Without loss of generality, we choose $\ell^*$ such that $F(\ell^*) = 1/e$, 
and let $\ell = a(\tilde b(c)) \ell^* + d(\tilde b(c))$. 
We may then calculate 
$$
\mathbf P\left[ \frac{T(\ell)}{b(1/p_{\ell})} > t \right]
= \mathbf P[T(\ell) > b(1/p_{\ell}) t]
= \mathbf P[V(ct) \le \ell]
$$
where we have substituted $c = b(1/p_{\ell})$ and used \eqref{inverserelat}. Moreover, we receive due to the convergence in \eqref{TheoMS}
$$
\mathbf P[V(ct) \le \ell]
= \mathbf P\left[ \frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\le \frac{\ell - d(\tilde b(c))}{a(\tilde b(c))} \right]
\longrightarrow \mathbf P\left[ Y(t) \le \ell^* \right] ,  \quad c \to \infty,
$$
for $t>0$. Defining the hitting time of level $\ell^*$ by $Y(t)$ as 
$\xi_{\ell^*} := \inf\{t: Y(t) > \ell^*\}$,
we then have 
$$
P\left[ Y(t) \le \ell^* \right] = \mathbf P[\xi_{\ell^*} > t] 
= \mathbf P[(-\log F(\ell^*))^{-1/\beta} X^{1/\beta} D > t]
$$
by [Proposition 4.2, @MeerschaertStoev08], where $X$ is an exponential 
random variable with mean $1$. 
Using [Theorem 19.1, @Haubold11], we see that 
$X^{1/\beta} D \sim {\rm ML}(\beta, 1)$, concluding the proof. 
\qed  

For a scale parameter $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma Z_\beta$. The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$ with mean $\sigma$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, for the purposes of applied statistics. 

We caution the reader that, somewhat confusingly, there is another distribution
called the "light-tailed" Mittag-Leffler distribution.  This is in fact the 
limiting distribution of the renewal process $N(t)$ above (see @limitCTRW). 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11, and for algorithms, see e.g. the R package `MittagLeffleR`
[@MittagLeffleR].


**Remark:**

: If $\beta = 1$, the result of the Theorem above is standard, see e.g. 
Equation (2.2) in @Gut1999. In @Anderson1987  a similar result is shown with a different choice of scaling constant. 

**Remark:**

: When $0 < \beta < 1$, the renewal process $N(t)$ is _not stationary_, 
and hence the results by @Hsing88 on the exceedances of stationary sequences
do not apply. 


# Model Choice and inference for the Mittag-Leffler distribution{#sec:ML}

The classical POT approach is based on the fact that exceedances above a high threshold are asymptotically GPD distributed, hence a GPD distribution is fitted to the exceedances above a high enough threshold. Due to the Theorem in the last Section we know that for high thresholds the times between exceedances are asymptotically Mittag-Leffler distributed in case of heavy-tailed waiting times between the observations. Hence, before we talk about inference for the exceedances in the next section, we discuss inference for Mittag-Leffler distributions.

Historically, the first method proposed for the estimation of the Mittag-Leffler distribution parameters was the fractional moment estimator by @kozubowski2001. Unlike the first moments, the fractional moments of order $p$ for $p<\beta$ exist and are tractable. One drawback of this method is that constant priors for the tail parameter are needed for the calculation of the estimates. @Cahoy2010 proposed a moment estimator of the log-transformed data, which does not require any prior. Furthermore, they performed simulation studies illustrating that the log-moment outperforms the fractional moment estimator with respect to bias and root mean squared error (RMSE).

Due to the form of the density function of a Mittag-Leffler distribution there exists no closed form for the Maximum Likelihood estimator (MLE). In the R Package `MittagLeffleR` [@MittagLeffleR], Maximum Likelihood estimation is implemented via numerical optimization. The MLE slightly outperforms the log-moment estimator regarding bias and RMSE for big enough sample sizes, but is extremely computationally intensive. Figure \ref{fig:MSE} shows that both estimators perform well, even for small sample sizes.

```{r MSE, echo=FALSE,warning=FALSE, fig.height=7,fig.width=8,fig.align="center", fig.cap="\\label{fig:MSE} MSE for the estimation of tail (left column) and scale (right column) parameters via log-moment estimator and MLE of a Mittag-Leffler sample with varying sample size n=25, 100, 200, varying tails on the x-axis and fixed scale equal to one.", out.width = '90%'}
load(here::here("article_springer", "article_springer_files", "ML_estim_simu","tbl_ges.RData"))
tbl_ges %>% 
  filter(n == "25" || n == "100" || n=="200") %>%
  filter(true.scale == "1") %>% 
  ggplot(aes(true.tail, mse, colour = method, group=method)) + 
  geom_line() + geom_point() + 
  facet_wrap(c("n","param"), scales = "free", ncol = 2) + 
  scale_color_manual(values=c("red", "blue"))
```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers would intuitively give the highest importance to the tail behaviour of the distribution. Of course, one can also use established tail exponent estimators for the estimation of the parameter $\beta$ such as the Hill estimator [@hill1975simple] based on the $r+1$ upper order statistics
\begin{align}\label{eq:Hill}
H_{r,n}=\left[ \frac{1}{r} \sum_{i=0}^{r} \log \frac{X_{(i)}}{X_{(r+1)}}\right]^{-1}, 
\end{align}
where $X_{(1)} \geq X_{(2)} \geq \ldots \geq X_{(n)}$ denote the order statistics in decreasing order of a sequence $X_1,\ldots,X_n$. However, these methods are statistically less efficient since they only use a portion of the information contained in the data, as mentioned by @kozubowski2001. Moreover, the Hill estimator requires a tuning parameter, denoted with $r$ in \eqref{eq:Hill}. Additionaly, the estimator only performs reliably well for distributions close to Pareto [see @Resnick97]. Figure \ref{fig:Hillplots} shows Hill plots for Mittag-Leffler simulated data, with varying sample sizes and tails. To deduce the correct tail parameter estimates from these plots is virtually impossible. To estimate the tail parameter of a Mittag-Leffler distribution with the Hill estimator, the sample size has to be much larger and one has to choose a large tuning parameter $r$. In case that only events above a high threshold are recorded, even $n=1000$ events are unrealistic. Furthermore the Hill estimator of course completely fails if the inter-arrival times are exponentially distributed and not heavy-tailed. We will come back to the problems with the Hill estimtator in Section \ref{Simulationstudy}.

```{r Hillplots, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{fig:Hillplots} Hillplots for simulated Mittag-Leffler data with true tail 0.8 and sample size 200 (left) and 1000 (right), with number of upper order statics r on which the Hill estimator is based on the x-axis. ", out.width = '90%'}
hill_estim<-function(k,data){
  n<-length(data)
  data<-sort(data)
  data_thinned<-data[(n-k):n]
  r<-1/k * sum(log(data_thinned/data_thinned[1]))
  return(1/r)
}


hill_estim_plot<-function(k_min,data,k_max=n,true_tail){
  n<-length(data)
  x_values<-k_min:k_max
  y_values<-sapply(x_values,hill_estim,data=data)
  df<-data.frame(x=x_values,y=y_values)
  ggplot2::ggplot(data=df,aes(x_values,y_values))+ geom_line(color="blue")+xlab("Order Statistics") + ylab("Hill-Estimator of Tail Index") +
  coord_cartesian(ylim=c(0,1.5)) + geom_hline(yintercept=true_tail, linetype="dashed", color = "red", size=0.5)
}

data_ml_1<-rml(n=200,tail=0.8,scale=1)
p1<-hill_estim_plot(k_min=30,data=data_ml_1,true_tail=0.8) +
  ggtitle("Hill plot, Mittag-Leffler data, n=200")

data_ml_2<-rml(n=1000,tail=0.8,scale=1)
p2<-hill_estim_plot(k_min=30,data=data_ml_2,true_tail=0.8) +
  ggtitle("Hill plot, Mittag-Leffler data, n=1000")

grid.arrange(p1,p2,ncol=2)
```

Since the exponential distribution is nested in the Mittag-Leffler family of 
distributions, a Likelihood-ratio Test (LRT) seems to be an appropriate way to choose 
between a model with exponential and Mittag-Leffler inter-exceedance times.
Although the two models are nested, the asymptotic distribution is not 
$\chi^2_1$-distributed, and Wilk's Theorem does not hold: under $H_0$, the 
parameter $\beta$ of Mittag-Leffler distribution is equal to $1$, and hence lies
on the boundary of the parameter space $(0,1]$. 
Instead, a valid approach is a bootstrapped Likelihood-ratio test [see e.g. @davison1997bootstrap]. 
Figure \ref{Fig:LRT} displays the (simulated) power for the bootstrapped LRT for Mittag-Leffler distributions with varying tail parameters based on 1000 simulation runs. As expected, the power decreases for tail parameters close to one, since the Mittag-Leffler distribution converges as $\beta \uparrow 1$ to an exponential distribution; it becomes hard to differentiate a Mittag-Lefller distribution from an exponential. 

```{r LRT_power, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{Fig:LRT} Power for bootstrapped LRT for different sample sizes, varying tails and scale parameter equal to 1.", out.width='90%'}
load(here::here("article_springer","article_springer_files","ML_LRT_simu","estimates_df_LRT_boot1_01.RData"))
df_LRT_boot_01 %>% filter(n=="20" || n=="50" || n=="100" || n=="200") %>% ggplot(aes(x=true.tail,y=power)) +  geom_line(aes(y=power,group=factor(n),color=factor(n),linetype=factor(n)),size=0.5)+
  scale_linetype_manual(values = c("solid","dashed","twodash","dotted"),name  ="Sample size")+
   labs(y="Power",x= "True tail parameter")+
  scale_color_manual(values=c("red", "blue","darkgreen","black"), name  ="Sample size") +
  ggtitle("Power of Likelihood-Ratio Test")
```


# Inference on Exceedance times

The Theorem in Section \ref{sec:scaling} implies that for a high 
threshold $\ell$ we may approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p_{\ell}))$ distribution, 
where the function $b(c)$ varies regularly at $\infty$ with parameter $1/\beta$.
Building on the POT (Peaks-Over-Threshold) method, we propose the following estimation procedure for the distribution of inter-exceedance time $T(\ell)$: 

1. Extract the $K$ largest order statistics 
(i.e. the $K$ largest values, where e.g. $K = 300$) 
$X_{(1)}, \ldots, X_{(K)}$ together with their timestamps $T_{(1)}, \ldots, T_{(K-1)}$. 

2. Choose e.g. $K_0 = 5$, and for each $k$ ranging from $K_0 +1$ to $K + 1$: 
    a) extract the set $\mathcal T_k$ of exceedance times of between the magnitudes exceeding the threshold $X_{(k)}$
    b) fit a Mittag-Leffler distribution to $\mathcal T_k$, resulting in the parameter
    estimates $\hat\beta_k$ and $\hat \sigma_k$.
  
3. Plot $k$ vs.\ $\hat \beta_k$. To the right, as $k \downarrow K_0$, the asymptotics are off and bias is high. To the left (high threshold), data are scarce and variance is high. Choose a region of *stability* in the middle for a parameter estimate $\hat \beta$.

4. Plot $k$ vs.\ $k^{1/\hat \beta} \hat \sigma_k$. Again, choose a region of *stability* as $k$ gets smaller and define $\hat \sigma_0$.

The inferred values $\hat \beta$ and $\hat \sigma_0$ can then be interpreted as follows: 
Setting the threshold at $X_{(k)}$, the threshold exceedance times follow a 
Mittag-Leffler distribution with shape parameter $\hat \beta$ and scale parameter
$\hat \sigma_0 k^{-1/\beta}$. 

To clarify Step 4: Recall that by the theorem, $\sigma_k / b(1/p_{\ell})$ is expected to stabilize 
around a constant as $k \downarrow K_0$. Since $b$ is regularly varying with parameter
$1/\beta$, we have $b(1/p_{\ell}) = p_{\ell}^{-1/\beta} / L(1/p_{\ell})$ for some slowly varying function $L$. 
Approximating $p_{\ell} \approx \hat p_{\ell} := k / n$, we have 
$$\text{const} \approx \sigma_k / b(1/p_{\ell}) = \sigma_k \times p_{\ell}^{1/\beta} L(1/p_{\ell}) \approx \sigma_k \times k^{1/\beta} n^{-1/\beta} L(n/k)$$
Assuming that the variation of $L(n/k)$ is minor, we can hence see that 
$\sigma_k k^{1/\beta}$ stabilizes.

For computationally efficient estimates of the Mittag-Leffler parameters we have used 
the method of log-transformed moments. This estimation method provides 
point estimates as well as confidence intervals based on sampling variance [@Cahoy2013], 
and has been implemented in the R software package
`MittagLeffleR` [@MittagLeffleR]. The stability plots for $\hat \beta$ and $\hat \sigma_0$
can be furnished with these confidence intervals, see e.g.\ Figure \ref{fig:flares}, 
to produce (non-simultaneous) confidence bands. 
These stability plots were produced with the R package `CTRE` [@CTRE]. 
We have verified the validity of our estimation algorithm  via simulations, 
see Section \ref{Simulationstudy}. 


# Simulation Study {#Simulationstudy} 

To test our inference method via stability plots, we have simulated $m=100$ times $n=10000$ independent waiting time and magnitude pairs $(W_k, J_k)$ for waiting times that follow


(i) a stable distribution,  


(ii) a Pareto distribution and


(iii) an exponential distribution.   



In order to have exact analytical values available for $\beta$ and $\sigma_0$, a distribution for $W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:stability} is known. 

**Case (i):** For (i) we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{eq:stability}, then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation [see e.g. the vignette on parametrisation in @MittagLeffleR]
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. By the Theorem, the distribution of $T(\ell)$ is approximately 
$$
{\rm ML}(\beta, p_{\ell}^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta}),
$$
which means 
$\sigma_0 = n^{1/\beta}$. 

**Case (ii):** In the Pareto example we choose $P(W>t)=Ct^{-\beta}$ with $C=(1/\Gamma(1-\beta))^{1/\beta}$. We have chosen $\beta=0.8$ in both cases (i) and (ii). 

**Case (iii):** We choose exponentially distributed waiting times with a rate 
parameter of $1$.

Figure \ref{Fig:TailSimu} shows the graphical "stability plots" for the 
estimation of the tail parameter, where 

+ rows correspond to cases (i), (ii) and (iii), and
+ columns correspond to estimators (log-moment estimator, maximum-likelihood, and Hill estimator). 

We plot the tail parameter estimates $\hat \beta(k)$ against $k$ 
for each of the $m=100$ simulation runs. 
Thin grey lines represent individual simulation runs, 
and the thicker black line is their mean. 
Recall that $k$ is the index of the order statistics of $J_k$ at which the 
threshold $\ell$ is placed. 
Note that the Hill estimator is based on the waiting times, not on the 
inter-exceedance times, meaning that the estimation is based on more data. 
If one were to base the Hill-estimation only on the inter-exceedance times, 
the sample size would be too small and it would be impossible to deduce an 
estimate for the tail parameter from the plots (compare Figure \ref{fig:Hillplots}). 

In the right-hand Hill-estimator column, the $k$ on the $x$-axis corresponds to
$r$ from \eqref{eq:Hill}.
The Hill estimator appears to be nicely unbiased on Pareto data,
but compared to the other two estimators, it has a higher variance, 
as can be seen from the wider spread of the simulated curves. 
This high variance means that that a single estimate is less reliable compared
to the other two estimators. 
This effect is amplified if one only has a thresholded, and thus smaller dataset
available, to the extent that the Hill estimates become severely flawed
(see Section \ref{sec:ML}). 

Moreover, the bottom in \ref{Fig:TailSimu} shows clearly that the log-moment 
and maximum-likelihod estimators generalize to the exponential case ($\beta = 1$), 
whereas the Hill-estimator does not. 

Finally, the performance of Log-Moment and Maximum-Likelihood estimators for the
scale parameter is shown in figure \ref{Fig:ScaleSimu}. 
Since there is no Hill-estimate of a scale parameter, there are only two columns. 
Both estimators show good performance, with a slight advantage for the 
Maximum-Likelihood estimator. This advantage is paid for by a higher computational 
cost. 

```{r TailSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:TailSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponentially distributed waiting times (lower row). Left column: log-moment estimator, middle column: MLE, right column: Hill estimator. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter. ", fig.show='hold', out.width = '100%'}

path <-
  here::here("article_springer",
             "article_springer_files",
             "Simulation_results")
files <- list.files(path)
file_dirs <- paste(path, "/", files, sep = "")
invisible(sapply(
  file_dirs,
  FUN = load,
  envir = .GlobalEnv,
  verbose = FALSE
))

#Tail Parameter

# Example One

#logMoment estimator
logMom_Ex1_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_tail08_logMoms_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_logMoms_Ex1) + 
  ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex1_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_tail08_mles_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex1) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#Hill estimator
hill_Ex1_tail <-
  ggplot() + geom_line(data = tbl_estimates_tail08_hill_Ex1,
                       aes(x = k, y = value, group = rep),
                       colour = "lightgrey") +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(data=means.tbl_hill_Ex1,aes(x=k, y=mw),colour="black") + 
  ylab("Estimated tail") +
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")


#Example Two

#logMoment estimator
logMom_Ex2_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Ex2_Pareto_tail08_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_logMoms_Ex2) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex2_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Ex2_Pareto_tail08_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_mles_Ex2) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#Hill estimator
hill_Ex2_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Ex2_Pareto_tail08_hill_times) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_hill_times_Ex2) + 
  ylab("Estimated tail") +
  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")

#Example Three

#logMoment estimator
logMom_Ex3_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Example3_Exp_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x = k, y = mw), colour = "black", data = means.tbl_logMoms_Ex3) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#ml estimator
mle_Ex3_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Example3_Exp_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex3) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#Hill estimator
hill_Ex3_tail <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_estimates_Example3_Exp_hill_times) +
  coord_cartesian(ylim = c(0.5, 10)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_hill_times_Ex3) + 
  ylab("Estimated tail") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")+ xlab("r")

grid.arrange(
  arrangeGrob(logMom_Ex1_tail,logMom_Ex2_tail,logMom_Ex3_tail,top="log-Moment"),
  arrangeGrob(mle_Ex1_tail, mle_Ex2_tail, mle_Ex3_tail,top="MLE"),
  arrangeGrob(hill_Ex1_tail,hill_Ex2_tail,hill_Ex3_tail,top="Hill"),
  ncol=3
)
```


```{r ScaleSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:ScaleSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponentially distributed waiting times (lower row). Left column: log-moment estimator, right column: MLE. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter.", fig.show='hold', out.width = '90%'}
#Scale Parameter

#Example One
logMom_Ex1_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_logMoms_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x = k, y = mw), colour = "black", means.tbl_scales_logMoms_Ex1) + 
  ylab("Estimated scale") +
  geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex1_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_mles_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex1) + 
  ylab("Estimated scale") +
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Two

logMom_Ex2_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_logMoms_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex2) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex2_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_mles_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex2) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Three

logMom_Ex3_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_logMoms_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex3) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red") 

mle_Ex3_scale <-
  ggplot() + geom_line(aes(x = k, y = value, group = rep),
                       colour = "lightgrey",
                       data = tbl_scales_mles_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex3) + 
  ylab("Estimated scale") + 
  geom_hline(yintercept=1, linetype="dashed", color = "red")

grid.arrange(
  arrangeGrob(logMom_Ex1_scale,logMom_Ex2_scale,logMom_Ex3_scale,top="log-Mom"),
  arrangeGrob(mle_Ex1_scale,mle_Ex2_scale,mle_Ex3_scale,top="MLE"),
  ncol = 2
)
```

# Data example

We now want to apply the proposed method to a real data example, the solar flare data which was already mentioned in Section 1 and can be seen in Figure \ref{fig:thresholdedBursty}. The data were extracted from the "complete Hard X Ray Burst Spectrometer event list", a comprehensive reference for all measurements of the Hard X Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,772 events were detected, with the "vast  majority being solar flares". To assure stationarity and due to missing values during the years 1983 and 1984, we based our analysis just on the year 1982, in which 2,488 events happened. The list includes the start time, peak time, duration, and peak rate of each event. We have used "start time" as the variable for event times, and "peak rate" as the variable for event magnitudes. 
 
Before we apply the POT approach described in Section 5 to the solar flare data, we first have to check if all model assumptions are fulfilled. The CTRE model is based on three main assumptions, which are repeated below. For each assumption, we suggest one means of checking if it holds: 

i.i.d.:

: After removing the "noise observations" below the smallest threshold 
  $\ell_0$, the pair sequence $(T(\ell_0, i), X(\ell_0,i))$ is i.i.d. 
  An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  

Uncoupled:

: Each $T(\ell, i)$ is independent of each $X(\ell, i)$. We propose an empirical copula
  plot to check for any dependence. 
  
  

${\rm ML}(\beta, \sigma)$ distribution of $T(\ell, i)$:

: Apply a cutoff at the lowest threshold $\ell_0$, 
  extract the threshold crossing times, 
  and create a QQ Plot for the Mittag-Leffler distribution. 
  Use a log-moment estimate of the tail parameter for the theoretical / population 
  quantiles of the plot.


Figures \ref{fig:flare-diagnostics-1}, \ref{fig:flare-diagnostics-2} and \ref{fig:flare-diagnostics-3} show the diagnostic plots for a minimum threshold chosen at the 200th order statistic. There is some residual autocorrelation for the sequence of threshold exceedance times that is not accounted for by the CTRE model.  

```{r flare-diagnostics-1, fig.height=7, fig.cap="\\label{fig:flare-diagnostics-1} Diagnostic plots for the solar flare data: auto-correlation function."}
flares_ctre <- flares %>% ctre() %>% thin(k = 150)
acf(flares_ctre)
```


```{r flare-diagnostics-2, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-2} Diagnostic plots for the solar flare data: empirical copula.",out.width="70%"}
empcopula(flares_ctre) + ggtitle("Empirical Copula: Exceedance Time vs. Exceedance")
```

```{r flare-diagnostics-3, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-3} Diagnostic plots for the solar flare data: QQ Plot.",out.width="70%"}
sample_data <- flares_ctre %>% interarrival()
n <- length(sample_data)

population_data <- MittagLeffleR::qml(p = stats::ppoints(n), tail = tail, 
  scale = 1)

extRemes::qqplot(x = log(sample_data), y = log(population_data), 
                 main = "QQ-plot Exceedance Times vs Mittag-Leffler",
                 xlab = "log Exceedance Times", 
                 ylab = "log Mittag-Leffler")
```

Figure \ref{fig:flares} shows the stability plots for the solar flare data, on the left for the tail parameter and on the right for the scale parameter. The dark grey ranges correspond to 95% confidence intervals, which are derived from the asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR]; dashed lines show the deduced true values of $\beta$ resp.\ $\sigma_0$. The stability plot for the tail stabilizes nicely around 0.85 (dashed line), while 
the scale parameter stabilizes less obviously near $3 \times 10^7$ (dashed line).
The growth of the scale parameter for lower threshold appears to be closer to linear in $p_{\ell}$, 
rather than proportional to $p_{\ell}^{1/0.85}$ as suggested by the Mittag-Leffler
fits. The reason for this is likely that the overall goodness of fit as 
compared to an exponential distribution is improved due to the 
peaked shape of the Mittag-Leffler distribution near $0$,
rather than its tail behaviour at $\infty$.
The reported fit should hence come with the caveat that a Mittag-Leffler 
distribution models exceedance times well only up to certain time-scales. 
More research is needed into the modelling of scale transitions, where
inter-exceedance times appear to have different power laws across different 
time scales.


```{r solar-flare-tail-scale, message=FALSE, fig.height=4.5, fig.width=8, fig.cap="\\label{fig:flares} Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset. Dotted horizontal lines are at $\\beta = 0.85$ and $\\sigma_0 = 3 \\times 10^7$ seconds $\\approx 0.95$ years."}
thin_flares_ctre <- flares %>% ctre() %>% thin(k = 700)
par(mfrow=c(1,2)) 
MLestimates(thin_flares_ctre, tail = 0.9, scale = 3 * 1E7)
```

The fit with a Mittag-Leffler distribution ($\beta = 0.85$) is good (see Figure \ref{fig:flare-diagnostics-3}), though there are signs that the power-law tail tapers off for very large inter-threshold crossing times. There is no apparent dependence between threshold exceedance times and event magnitudes seen in the copula plot (see Figure \ref{fig:flare-diagnostics-2}). We also counduct a bootstrapped LRT for the null hypothesis of exponentially distributed inter-arrival times and received a $p$-value of $p<0.01$. 

# Predicting the time of the next threshold crossing

According to Figure \ref{fig:flares}, for a threshold $\ell$ at the $k$-th order 
statistic, the estimated threshold exceedance time distribution is 
$$
T(\ell) \sim {\rm ML}(\beta, k^{-1/\beta} \sigma_0), 
$$
where $\beta = 0.85$ and $\sigma_0 = 3.0 \times 10^7 {\rm sec}$. 
Unlike the exponential distribution, the Mittag-Leffler distribution is not memoryless, and the probability density of the time $t$ until the next threshold crossing will depend on the time $t_0$ elapsed since the last threshold crossing.
This density is approximately equal to 
$$
p(t|\beta, \sigma_0, \ell, t_0) \approx \frac{f(t + t_0 | \beta, k^{-1/\beta} \sigma_0)}{\mathbf P[T_\ell > t_0]}
$$
where $f(\,\cdot\, | \beta, k^{-1/\beta} \sigma_0)$ is the probability density of ${\rm ML}(\beta, k^{-1/\beta} \sigma_0)$. 
The more time has passed without a threshold crossing, the more the probability distribution shifts towards larger values for the next crossing
(see Figure \ref{fig:hazard}, left panel). The hazard rate 
$$
h(t) = \frac{f(t| \beta, k^{-1/\beta} \sigma_0))}{\int_t^\infty f(\tau| \beta, k^{-1/\beta} \sigma_0))\,d\tau}
$$
represents the risk of a threshold crossing per unit time, and is a decreasing function for the Mittag-Leffler distribution. 
```{r hazard, fig.height=4, fig.cap="\\label{fig:hazard} Left: Conditional distribution of time until next threshold crossing, depending on elapsed time $t_0$ since last crossing ($\\beta = 0.8$, $\\sigma_0 = 1$). Right: Hazard rate depending on tail parameter $\\beta$."}
tail <- 0.7
scale <- 1
t_0 <- c(0, 1, 10)
from <- 0.1
to <- 100 * scale
xx <- exp(seq(from = log(from), to = log(to), length.out = 100))
par(mfrow = c(1,2))
df1<-data.frame(x=xx,y=rep(1, length(xx)))
col<-c("red","blue","darkgreen","black")

plot(xx, rep(1, length(xx)), ylim = c(0.001,1), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'p', main = "Next Threshold Crossing Time")
for (k in 1:length(t_0)) {
  cond <- pml(q = t_0[k], tail = tail, scale = scale, lower.tail = FALSE)
  yy <- dml(x = xx + t_0[k], tail = tail, scale = scale) / cond
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("t_0 = 0", "t_0 = 1", "t_0 = 10"), col = c("red","blue","darkgreen"), lty = 2:4)

betas <- c(0.7, 0.8, 0.95, 0.99)
t_0 <- 1

plot(xx, rep(1, length(xx)), ylim = c(0.001,2), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'h', main = "Mittag-Leffler Hazard Rate")
for (k in 1:length(betas)) {
  yy <- dml(x = xx, tail = betas[k], scale = scale) / pml(
    q = xx,
    tail = betas[k],
    scale = scale,
    lower.tail = FALSE
  )
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("beta = 0.7", "beta = 0.8", "beta = 0.95", "beta = 0.99"), col = c("red","blue","darkgreen","black"), lty = 2:5)

```
The closer $\beta$ is to $1$, the more the hazard rate mimics that of an 
exponential distribution (a constant function, see Figure \ref{fig:hazard}, 
right panel). 


# Discussion & Conclusion

We have extended the POT (Peaks-over-Threshold) model, a mainstay of extreme value theory, to "bursty" time series, which have been studied 
intensively in statistical physics. Burstiness is characterized by power-law waiting times between events, and we have shown that the Mittag-Leffler distribution arises naturally as a scaling limit for the inter-exceedance times of high thresholds. Moreover, we have derived the following non-linear scaling behaviour: $\sigma \sim p_{\ell}^{-1/\beta}$, where $\sigma$ is the scale parameter of the distribution of threshold 
exceedance times, $p_{\ell}$ is the fraction of magnitudes above the threshold, and $\beta$ the exponent of the power law. 
This "anomalous" scaling behaviour in the bursty setting entails two phenomena: 

i) a heavy tail of the inter-arrival time distribution of threshold crossings (long rests), and 

ii) a high propensity for more threshold crossing events immediately after each threshold crossing event (bursts). 

The Mittag-Leffler distribution captures both phenomena, due to its heavy tail as well as its stretched exponential (peaked) asymptotics for small times. It generalizes the exponential distribution, and in the solar flare data example, this generalization is warranted, because the likelihood-ratio test is strongly significant. 

When we introduced the CTRE model, we assumed that all events are i.i.d. This assumption is likely sufficient but not necessary for our limit theorem to hold. Moreover, any data below a (minimum) threshold $\ell_0$ is discarded for CTREs, and hence need not satisfy the i.i.d. assumption. For the purposes of statistical inference, we merely require that the inter-threshold-crossing times are i.i.d. 

The bursty CTRE approach to model "non-Poissonian" threshold crossing times should be contrasted with the (now standard) approach of clusters of extremes, see e.g. @ferro2003inference. In this approach, i.i.d. event sequences of magnitudes are generalized to stationary sequences of
event magnitudes (subject to a mixing condition). The two approaches are fundamentally different: A clustering model assumes that each event 
belongs to one particular (latent) group of events. For bursts, however, the aim is to identify an underlying scale-free pattern in the event 
dynamics, which is often characteristic of complex systems. It is an interesting open problem to develop quality criteria, based
e.g. on measures of surprise [@Lee15], which guide an applied statistician in the choice between a clustering and a CTRE approach for a particular problem. Moreover, we believe it may be possible to unify the two approaches by considering CTREs based on MRPs with a _stationary_, rather than i.i.d., sequence of magnitudes. 

Finally, a purely scale-free pattern for event times may be too rigid as an 
assumption for some bursty time series, because often the heavy-tailed character of the inter-arrival time
distribution does not hold at all time scales; rather, it applies at short and intermediate time scales, and is truncated (or tempered, 
reverting to an exponential distribution) at very long time scales [see e.g. @MeerschaertRoyQin; and @Aban06]. In such situations, a "tempered" Mittag-Leffler distribution may provide a more realistic fit, which we aim to introduce in follow-up work. 

# Acknowledgements {-}

The authors would like to thank Prof. Peter Scheffler for insights on stochastic process limits for CTRMs, Prof. Roland Fried for discussion regarding the statistical methods and Gurtek Gill who helped create the MittagLeffleR R-package. 


\newpage

# References {-}

