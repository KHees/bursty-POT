---
title: "Statistical Inference for inter-arrival times of extreme events in bursty time series"
# titlerunning: "CTRE: POT for Bursty Time Series"
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
author: 

- name: "Katharina Hees"
  affiliation: a
  email: "hees@statistik.tu-dortmund.de"
  
- name: "Smarak Nayak"
  affiliation: b
  email: "smarak.nayak@nab.com.au"
  
- name: "Peter Straka"
  affiliation: c
  email: "p.straka@unsw.edu.au"
  
address:

- code: a
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

- code: b
  address: "National Australia Bank, Melbourne, Australia"
    
- code: c
  address: "School of Mathematics and Statistics, UNSW, Sydney, Australia"
    
corrauth:
  name: "Katharina Hees"
  address: "Department of Statistics, TU Dortmund University, Dortmund, Germany"

authorrunning: K. Hees, S. Nayak & P. Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex systems studied in statistical physics, 
  inter-arrival times between events such as solar flares, trades and 
  neuron voltages follow a heavy-tailed distribution. The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon which has been dubbed 
  "bursty". 
  
  This article proposes a new model for the _inter-exceedance times_ of events 
  above high thresholds; the threshold exceedances itself are modeled via the standard 
  Peaks-Over-Threshold (POT) method. For high thresholds and 
  infinite-mean waiting times, we show that the times between threshold 
  crossings are Mittag-Leffler distributed, and thus form a "fractional 
  Poisson Process" which generalizes the standard Poisson Process of threshold
  exceedances.
  We provide graphical means of estimating model parameters and assessing 
  model fit. Along the way, we apply our inference method to a real-world
  bursty time series, and 
  show how the memory of the Mittag-Leffler distribution affects 
  the predictive distribution for the time until the next extreme event. 

bibliography: CTRMstats.bib
csl: 
output: 
       rticles::elsevier_article:
                fig_caption: yes
                number_sections: true
                

params:
  tail: 0.8
  n: 10000

header-icludes: \usepackage{amssymb,natbib}


---

```{r get-rticles, eval=FALSE, include=FALSE, cache=TRUE}
# use this rticles version: 
devtools::install_github("rstudio/rticles")
# use the newest MittagLeffleR version:
devtools::install_github("strakaps/MittagLeffleR")
library(MittagLeffleR)
devtools::install_github("strakaps/CTRE")
library("CTRE")
library(CTRE)
install.packages("here")
library(here)
Sys.setenv(TEXINPUTS=getwd(),
           BIBINPUTS=getwd(),
           BSTINPUTS=getwd())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3, out.width = '\\textwidth'
  )
library(CTRE)
library(MittagLeffleR)
library(magrittr)
library(gridExtra)
library(ggplot2)
library(dplyr)
set.seed(12345)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour in terms of the occurrence of events have received strong interest in the recent statistical physics literature [@Barabasi2005;@Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; @Min2010; @Karsai2011;@Bagrow2013]. They have been observed in the context of earthquakes, sunspots, neuronal activity and human communication [see @Karsai2012; @Vajna2013; @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point process by @hawkes1971point), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, solar flares or neuron voltages. 
The Peaks-Over-Threshold model [POT, see e.g. @ColesBook] applies a
threshold to the magnitudes, and fits a Generalized Pareto distribution 
to the threshold exceedances. 
A commonly made assumption in POT models is that times between 
events are either fixed 
or light-tailed, and this entails that the 
threshold crossing times form a Poisson process [@Hsing88]. 
Then as one increases the threshold and thus decreases the threshold 
crossing probability $p$, the Poisson process is rarefied, i.e. its 
intensity decreases _linearly_ with $p$ [see e.g. @beirlantBook]. 

As will be shown below, in the heavy-tailed waiting time scenario threshold 
crossing times form a _fractional Poisson process_ 
[@Laskin2003; @Meerschaert2010b], which is a 
renewal process with Mittag-Leffler distributed waiting times. 
The family of Mittag-Leffler distributions nests the exponential 
distribution [@Haubold11], and hence the fractional Poisson process
generalizes the standard Poisson process. 
Again as the threshold size increases and the threshold crossing
probability $p$ decreases, the fractional Poisson process is rarefied: 
The scale parameter of the Mittag-Leffler inter-arrival times of 
threshold crossing times increases, but _superlinearly_; 
see the Theorem below.


Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @hees2016joint; @hees2017coupled], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, which is seemingly not available in the literature.

We review the marked renewal process in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Section 3.
We give a statistical procedure to estimate model parameters via stability plots 
in Section 5, but to set the stage we first discuss inference for the 
Mittag-Leffler distribution in Section 4. A simulation study of the effectiveness of our statistical procedure is given in Section 6. In Section 7 we apply our method to a real data set.  In Section 8, we discuss the memory property of the  Mittag-Leffler distribution, and how it affects the predictive distribution for the time until the next threshold crossing event. Finally we close with a discussion and conclusion in Section 9.
For all statistical computations we have used R [@R]. 
All code and data used for the analysis in this article has been organized into 
an R package `CTRE` (<https://github.com/strakaps/CTRE>).
The source code for the figures generated in this manuscript is 
available online at <https://github.com/strakaps/bursty-POT>. 


# Continuous Time Random Exceedances (CTRE)

As a model for extreme observations, we use a Marked Renewal Process (MRP):

**Definition (MRP):** 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the *waiting times* 
and $J_k \in [x_L, x_R]$ as the *event magnitudes* 
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
If $W$ and $J$ are independent, the Marked Renewal Process is said to be *uncoupled*. 


We assume that the $k$-th magnitude $J_k$ occurs at time
$T_k = W_1 + \ldots + W_k$. 
Based on an MRP, we define the Continuous Time Random Exceedance model
(CTRE) as follows:

**Definition (CTRE):** 

: Given a threshold $\ell \in (x_L, x_R)$, 
consider the stopping time 
$$\tau(\ell) := \min\{k: J_k > \ell\},\quad \ell \in (x_L, x_R).$$
Define the pair of random variables $(X(\ell), T(\ell))$ via 
$$X(\ell) = J_{\tau(\ell)} - \ell, \quad 
T(\ell) = \sum_{k=1}^{\tau(\ell)} W_k.$$
By restarting the MRP at $\tau(\ell)$, inductively define the
two i.i.d. sequences $T(\ell,n)$ and $X(\ell, n)$, $n \in \mathbb N$, 
called the "inter-arrival times" and the "exceedances", respectively.
The pair sequence $(T(\ell, n), W(\ell, n))_{n \in \mathbb N}$ is called 
a Continuous Time Random Exceedance model (CTRE). 
If the underlying MRP is uncoupled, then the CTRE is also called 
uncoupled. 


```{r thresholdedBursty, message=FALSE, fig.height=6, fig.width=7,out.width='70%',fig.align='center',fig.cap="\\label{fig:thresholdedBursty} Exceedances (red) and times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line). Upper picture: Simulated data with stable distributed waiting times. Lower picture: Solar flares during 1982."}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctre <- ctre(data.frame(times, magnitudes)) 
p1<-plot(sim_ctre, p = 0.01, main = "Simulated MRP") 
p2<-flares %>% ctre() %>% plot(p = 0.02, log = 'y', main = "HXRBS data") 
grid.arrange(p1,p2)

```

In this article, we restrict ourselves to the uncoupled case, where $W$ and $J$ are independent. Then the two sequences $X(\ell, n)_{n \in \mathbb N}$ and $T(\ell, n)_{n \in \mathbb N}$ are independent as well. To see why, note that $X(\ell)$ is, in distribution, simply equal to $J | J > \ell$, independent of any waiting time $W_k$.  
Figure \ref{fig:thresholdedBursty} shows a simulated dataset in the top panel, where $W$ has a stable distribution with tail parameter $\beta =$ `r params$tail` (and skewness $1$ and location $0$), and where $J$ is from a standard Gumbel distribution. In the bottom panel, we plot a time series of solar flare intensities derived from a NASA dataset [@HXRBS] which we will later examine more closely (see Section 7). Clearly, the simulated data exhibit long intervals 
_without any_ events, whereas in the real-world dataset events appear continuously. The threshold exceedances, however, appear to have visually similar statistical behaviour in both models. Observations below a threshold are commonly discarded in Extreme Value Theory (POT approach); likewise, the CTRE model interprets these observations as noise and discards them.

# Scaling limit of Exceedance Times {#sec:scaling}

In this section we state and prove the key theorem, see below. For an accessible introduction to regular variation and stable limit theorems, we recommend the book by @MeerschaertSikorskii.

**Theorem:** 

: Let the waiting times $J_k$ be in the domain of attraction of a positively skewed sum-stable law with stability parameter $0 < \beta < 1$; more precisely,
\begin{align} \label{eq:stability}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
for a function $b(n)$ which is regularly varying at $\infty$ with parameter $1/\beta$, and where $\mathbf E[\exp(-sD)] = \exp(-s^\beta)$. Write $p := \mathbf P(J > \ell)$. Then the weak convergence
$$
\frac{T(\ell)} {b(1/p)} \to W_\beta \quad \text{ as } \quad \ell \uparrow x_R
$$
holds, where the Mittag-Leffler random variable $W_\beta$ is defined on 
the positive real numbers via 
$$
\mathbf E[\exp(-sW_\beta)] = \frac{1}{1+s^\beta}.
$$ 


*Proof of Theorem:* We interpret the threshold crossing time $T(\ell)$ as the hitting time of the 
underlying CTRM (Continuous Time Random Maxima) or "max-renewal process", 
and then utilize a result by @MeerschaertStoev08. 
The running maximum process is defined as 
$$
M(c) := J_1 \vee \ldots \vee J_{\lfloor c \rfloor},
$$
and since we assume that the $J_k$ have a continuous distribution, there exist 
norming functions $a(c)$ and $d(c)$ such that 
$$
\mathbf P\left[ \frac{M(c) - d(c)}{a(c)} \le \ell^* \right] 
\longrightarrow F(\ell^*), \quad t \to \infty
$$
where $F$ is a generalized extreme value distribution, and $\ell^*$ is any 
value from the support of $F$. 
The CTRM process is then defined via 
$$
V(t) = M(N(t)), \quad t \ge 0
$$
where $N(t)$ is the renewal process associated with the waiting times 
$W_k$: 
$$
N(t) = \max\{n: W_1 + \ldots + W_n \le t\}.
$$
Now a key observation is that
$$
T(\ell) = \inf\{t: V(t) > \ell\}, 
$$
and that 
$$
T(\ell) > t \quad \text{ if and only if } \quad V(t) \le \ell.
$$
By [Theorem 3.1, @MeerschaertStoev08], we have the stochastic process 
convergence 
$$
\frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\stackrel{d}{\longrightarrow} Y(t), \quad t > 0.
$$
where $Y(t)$ is a time-changed ("subordinated") extremal process, and where 
$\tilde b(c)$ is a regularly varying norming function which is
_inverse_ to $b(c)$, in the sense that 
$b(\tilde b(c)) \sim c \sim \tilde b(b(c))$. 

Without loss of generality, we choose $\ell^*$ such that $F(\ell^*) = 1/e$, 
and let $\ell = a(\tilde b(c)) \ell^* + d(\tilde b(c))$. 
We may then calculate 
$$
\mathbf P\left[ \frac{T(\ell)}{b(1/p)} > t \right]
= \mathbf P[T(\ell) > b(1/p) t]
= \mathbf P[V(ct) \le \ell]
$$
where we have substituted $c = b(1/p)$. Moreover 
$$
\mathbf P[V(ct) \le \ell]
= \mathbf P\left[ \frac{V(ct) - d(\tilde b(c))}{a(\tilde b(c))} 
\le \frac{\ell - d(\tilde b(c))}{a(\tilde b(c))} \right]
\longrightarrow \mathbf P\left[ Y(t) \le \ell^* \right]
$$
Defining the hitting time of level $\ell^*$ by $Y(t)$ as 
$\xi_{\ell^*} := \inf\{t: Y(t) > \ell^*\}$,
we then have 
$$
P\left[ Y(t) \le \ell^* \right] = \mathbf P[\xi_{\ell^*} > t] 
= \mathbf P[(-\log F(\ell^*))^{-1/\beta} X^{1/\beta} D > t]
$$
by [Proposition 4.2, @MeerschaertStoev08], where $X$ is an exponential 
random variable with mean $1$. 
Using [Theorem 19.1, @Haubold11], we see that 
$X^{1/\beta} D \sim {\rm ML}(\beta, 1)$, concluding the proof. 
\qed  

For a scale parameter $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution of $\sigma W_\beta$. The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
a heavy-tailed positive distribution for $\beta < 1$, with infinite mean. 
However, as $\beta \uparrow 1$, ${\rm ML}(\beta, \sigma)$ converges 
weakly to the exponential distribution ${\rm Exp}(\sigma)$ with mean $\sigma$.
This means that although its moments are all infinite, the Mittag-Leffler
distribution may (if $\beta$ is close to 1) be indistinguishable from the 
exponential distribution, for the purposes of applied statistics. 
For a detailed reference on the Mittag-Leffler distribution, see e.g. 
@Haubold11, and for algorithms, see e.g. the R package `MittagLeffleR`
[@MittagLeffleR].


**Remark:**

: If $\beta = 1$, the result of the Theorem above is standard, see e.g. 
Equation (2.2) in @Gut1999. In @Anderson1987  a similar result is shown with a different choice of scaling constant. 


# Model Choice and inference for the Mittag-Leffler distribution{#sec:ML}

The classical POT approach is based on the fact that exceedances above a high threshhold are asymptotically GPD distributed, hence a GPD distribution is fitted to the exceedances above a high enough threshhold. Due to the Theorem in the last Section we know that for high thresholds the times between exceedances are asymptotically Mittag-Leffler distributed in case of heavy-tailed waiting times between the observations. Hence, before we talk about inference for the exceedances in the next section, we discuss inference for Mittag-Leffler distributions.

Historically, the first method proposed for the estimation of the Mittag-Leffler distribution parameters was the fractional moment estimator by @kozubowski2001. Unlike the first moments, the fractional moments of order $p$ for $p<\beta$ exist and are tractable. One drawback of this method is that constant priors for the tail parameter are needed for the calculation of the estimates. @Cahoy2010 proposed a moment estimator of the log-transformed data, which does not require any prior. Furthermore, they performed simulation studies illustrating that the log-moment outperforms the fractional moment estimator with respect to bias and root mean squared error (RMSE).

Due to the form of the density function of a Mittag-Leffler distribution there exists no closed form for the Maximum Likelihood estimator (MLE). In the R Package `MittagLeffleR` [@MittagLeffleR], Maximum Likelihood estimation is implemented via numerical optimization. The MLE slightly outperforms the log-moment estimator regarding bias and RMSE for big enough sample sizes, but is extremely computational intensive. Figure \ref{fig:MSE} shows that both estimators perform well, even for small sample sizes.

```{r MSE, echo=FALSE,warning=FALSE, fig.height=7,fig.width=8,fig.align="center", fig.cap="\\label{fig:MSE} MSE for the estimation of tail (left column) and scale (right column) parameters via log-moment estimator and mle of a Mittag-Leffler sample with varying sample size n=25, 100, 200, varying tails on the x-axis and fixed scale equal to one.", out.width = '90%'}
load(here::here("article_springer\\article_springer_files\\ML_estim_simu","tbl_ges.RData"))
tbl_ges %>% 
  filter(n == "25" || n == "100" || n=="200") %>%
  filter(true.scale == "1") %>% 
  ggplot(aes(true.tail, mse, colour = method, group=method)) + 
  geom_line() + geom_point() + 
  facet_wrap(c("n","param"), scales = "free", ncol = 2) + 
  scale_color_manual(values=c("red", "blue"))
```

Since the Mittag-Leffler distribution is heavy-tailed, many researchers would intuitively give the highest importance to the tail behaviour of the distribution. Of course, one can also use established tail exponent estimators for the estimation of the parameter $\beta$ such as the Hill estimator [@hill1975simple] based on the $r+1$ upper order statistics
\begin{align}\label{eq:hill}
H_{r,n}=\left[ \frac{1}{r} \sum_{i=0}^{r} \log \frac{X_{(i)}}{X_{(r+1)}}\right]^{-1}, 
\end{align}
where $X_{(1)} \geq X_{(2)} \geq \ldots \geq X_{(n)}$ denote the order statistics in decreasing order of a sequence $X_1,\ldots,X_n$. However, these methods are statistically less efficient since they only use a portion of the information contained in the data, as mentioned by @kozubowski2001. Moreover, the hill estimator requires a tuning parameter, denoted with $r$ in \eqref{eq:hill}. Additionaly, the estimator only performs reliably well for distributions close to Pareto [see @Resnick97]. Figure \ref{fig:Hillplots} shows Hill plots for Mittag-Leffler simulated data, with varying sample sizes and tails. To deduce the correct tail parameter estimates from these plots is virtually impossible. To estimate the tail parameter of a Mittag-Leffler distribution with the hill estimator, the sample size has to be much larger and one has to choose a large tuning parameter $r$. In case that only events above a high threshold are recorded, even $n=1000$ events are unrealistic. Furthermore the Hill estimator of course completely fails if the inter-arrival times are exponential distributed and not heavy-tailed. We will comeback to the problems with the hill estimtator in Section \ref{Simulationstudy}.

```{r Hillplots, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{fig:Hillplots} Hillplots for simulated Mittag-Leffler data with true tail 0.8 and sample size 200 (left) and 1000 (right), with number of upper order statics r on which the hill estimator is based on the x-axis. ", out.width = '90%'}
hill_estim<-function(k,data){
  n<-length(data)
  data<-sort(data)
  data_thinned<-data[(n-k):n]
  r<-1/k * sum(log(data_thinned/data_thinned[1]))
  return(1/r)
}


hill_estim_plot<-function(k_min,data,k_max=n,true_tail){
  n<-length(data)
  x_values<-k_min:k_max
  y_values<-sapply(x_values,hill_estim,data=data)
  df<-data.frame(x=x_values,y=y_values)
  ggplot2::ggplot(data=df,aes(x_values,y_values))+ geom_line(color="blue")+xlab("Order Statistics") + ylab("Hill-Estimator of Tail Index") +
  coord_cartesian(ylim=c(0,1.5)) + geom_hline(yintercept=true_tail, linetype="dashed", color = "red", size=0.5)
}

data_ml_1<-rml(n=200,tail=0.8,scale=1)
p1<-hill_estim_plot(k_min=30,data=data_ml_1,true_tail=0.8)

data_ml_2<-rml(n=1000,tail=0.8,scale=1)
p2<-hill_estim_plot(k_min=30,data=data_ml_2,true_tail=0.8)
grid.arrange(p1,p2,ncol=2)
```

Since the exponential distribution is nested in the Mittag-Leffler family of 
distributions, a Likelihood-ratio Test (LRT) seems to be an appropriate way to choose 
between a model with exponential and Mittag-Leffler inter-exceedance times.
Although the two models are nested, the asymptotic distribution is not 
$\chi^2_1$-distributed, and Wilk's Theorem does not hold: under $H_0$, the 
parameter $\beta$ of Mittag-Leffler distribution is equal to $1$, and hence lies
on the boundary of the parameter space $(0,1]$. 
Instead, a valid approach is a bootstrapped Likelihood-ratio test [see e.g. @davison1997bootstrap]. 
Figure \ref{Fig:LRT} displays the (simulated) power for the bootstrapped LRT for Mittag-Leffler distributions with varying tail parameters based on 1000 simulation runs. As expected, the power decreases for tail parameters close to one, since the Mittag-Leffler distribution converges as $\beta \uparrow 1$ to an exponential distribution; it becomes hard to differentiate a Mittag-Lefller distribution from an exponential. 

```{r LRT_power, echo=FALSE,warning=FALSE, fig.align="center", fig.cap="\\label{Fig:LRT} Power for bootstrapped LRT for different sample sizes , varying tails and scale parameter equal to 1.",out.width='90%'}
load(here::here("article_springer","article_springer_files","ML_LRT_simu","estimates_df_LRT_boot1_01.RData"))
df_LRT_boot_01 %>% filter(n=="20" || n=="50" || n=="100" || n=="200") %>% ggplot(aes(x=true.tail,y=power)) +  geom_line(aes(y=power,group=factor(n),color=factor(n),linetype=factor(n)),size=0.5)+
  scale_linetype_manual(values = c("solid","dashed","twodash","dotted"),name  ="Sample size")+
   labs(y="Power",x= "True tail parameter")+
  scale_color_manual(values=c("red", "blue","darkgreen","black"), name  ="Sample size")
```

# Inference on Exceedance times


The Theorem in Section \ref{sec:scaling} implies that for a high 
threshold $\ell$ we may approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution, 
where the function $b(c)$ varies regularly at $\infty$ with parameter $1/\beta$.
Building on the POT (Peaks-Over-Threshold) method, we propose the following estimation procedure for the distribution of inter-exceedance time $T(\ell)$: 

1. For a range of thresholds $\ell$ near the largest order statistics, extract datasets of exceedance times $\{T(\ell, i)\}_i$.
  
2. For each choice of threshold $\ell$, fit a Mittag-Leffler distribution to the resulting dataset
  $\{T(\ell, i)\}_i$.  This results in the estimates $\{\hat\beta(\ell)\}_\ell$ and $\{\hat \sigma(\ell)\}_\ell$.
  
3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. Use $\hat \beta$ as an estimate for the tail      parameter $\beta$ of the Mittag-Leffler distribution of exceedance times. 
  

4. Approximate $p \approx |\{k: J_k > \ell\}| / n$. 
  Recall that $b(c)$ is regularly varying with parameter $1/\beta$, and 
  hence has the representation $b(c) = L(c) c^{1/\beta}$ for some 
  slowly varying function $L(c)$. 
  Assuming that the variation of $L(c)$ is negligible, we hence 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ is expected to stabilize around a constant 
  $\hat \sigma_0$. 
  We then use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 

The above approach benefits from the following
practical adjustments (compare with Figure \ref{fig:flares}):

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
  
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 

* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by the multiplicative constant $n^{1/\hat \beta}$, 
  but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0),
\end{align*}
where $\ell$ equals the $k$-th order statistic.
For quick estimates of the Mittag-Leffler parameters we have used 
the method of log-transformed moments [@Cahoy2013].
We have verified the validity of our estimation algorithm  via simulations, 
see Section \ref{Simulationstudy}. 


# Simulation study{#Simulationstudy} 

To test our inference method via stability plots, we have simulated $m=100$ times $n=10000$ independent waiting time and magnitude pairs $(W_k, J_k)$ for waiting times that follow


(i) a stable distribution,  


(ii) a Pareto distribution and   


(iii) an exponential distribution.   



In order to have exact analytical values available for $\beta$ and $\sigma_0$, a distribution for $W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:stability} is known. For (i) we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{eq:stability}, then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation [see e.g. the vignette on parametrisation in @MittagLeffleR]
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. By the Theorem, the distribution of $T(\ell)$ is approximately 
$$
{\rm ML}(\beta, p^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta}),
$$
which means 
$\sigma_0 = n^{1/\beta}$. In the Pareto example we choose $P(W>t)=Ct^{-\beta}$ with $C=(1/\Gamma(1-\beta))^{1/\beta}$. We have chosen $\beta=0.8$ in the stable as well as in the Pareto case. As third example we choose exponential distributed waiting times with a rate of $1$. Figure \ref{Fig:TailSimu} shows the stability plots for the estimation of the tail parameter. Therefore, $\hat \beta(k)$ vs. $k$ is plotted for each of the $m=100$ simulation runs (grey thin lines). In the left column one can see the estimates based on the log-moment estimator, the stability plots in the middle are based on the maximum-likelihood estimator and on the right hand on the hill estimator. Recall that $k$ is the index of the order statistics of $J_k$ at which the threshold $\ell$ is placed. Note, that the hill estimator is here based on the waiting times, not on the inter-exceedance times, hence the estimation is based on much more data. If one would base the hill-estimation only on the inter-exceedance times, the sample size would be too small and it would be impossible to deduce an estimate for the tail parameter from the plots (compare Figure \ref{fig:Hillplots}). The $k$ on the $x-$axis is in the plots for the hill estimator the $r$ which defines on which upper orders stats the hill estimator is based on (compare \eqref{eq:hill}). The bigger sample size results in the middle in a lower bias. But, one can also see, that there is much more variance between the stability plots for the different simulation runs in case of the hill estimator compared to the other two estimators. The black line is the mean value of the point estimators for each $k$ resp. $r$. However, if one wants to get a single estimate via such a stability plot, it would be much more difficult to deduce it from a hill plot compared to the other two estimators. In case that one has only thresholded data and hence a much smaller simple size, the hill estimator gets useless (see Section \ref{sec:ML}). Another advantage of the other estimators compared to the hill estimator is, that in the case one has exponential waiting times, the log-moment as well as the mle can detect this by getting an estimate close to $1$. The hill estimators is just a tail parameter estimator for Pareto like tails and hence of course fails in case of exponential distributed inter-exceedance times. Figure \ref{Fig:ScaleSimu} shows the stability plots for the different estimators for the scale parameter. Here of course only for the log-moment (on the right hand)  and the mle (on the left hand), since the hill estimator is just a tail parameter estimate. Here again both estimators show good performance. The stability plots in the mle case are a little bit closer to the true value, except in the exponetial case. Therefore, the mle is much more computational intensive. 

```{r TailSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:TailSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponential distributed waiting times (lower row). Left column: log-moment estimator, middle column: MLE, right column: Hill estimator. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter. ", fig.show='hold', out.width = '100%'}

path<-here::here("article_springer/article_springer_files/Simulation_results")
files<-list.files(path)
file_dirs<-paste(path,"/",files,sep="")
invisible(sapply(file_dirs,FUN=load,envir=.GlobalEnv,verbose=FALSE))

#Tail Parameter

# Example One

#logMoment estimator
logMom_Ex1_tail<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_tail08_logMoms_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_logMoms_Ex1) + ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex1_tail<-ggplot() + geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_tail08_mles_Ex1) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex1) + ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#Hill estimator
hill_Ex1_tail<-ggplot()+ geom_line(data=tbl_estimates_tail08_hill_Ex1,aes(x=k,y=value,group=rep),colour="lightgrey") +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(data=means.tbl_hill_Ex1,aes(x=k, y=mw),colour="black") + ylab("Estimated tail") +  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")


#Example Two

#logMoment estimator
logMom_Ex2_tail<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Ex2_Pareto_tail08_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_logMoms_Ex2) + ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#ml estimator
mle_Ex2_tail<-ggplot() + geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Ex2_Pareto_tail08_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex2) + ylab("Estimated tail") + geom_hline(yintercept=0.8, linetype="dashed", color = "red")

#Hill estimator
hill_Ex2_tail<-ggplot() + geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Ex2_Pareto_tail08_hill_times) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_hill_times_Ex2) + ylab("Estimated tail") +  geom_hline(yintercept=0.8, linetype="dashed", color = "red")+ xlab("r")

#Example Three

#logMoment estimator
logMom_Ex3_tail<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Example3_Exp_logMoms) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_logMoms_Ex3) + ylab("Estimated tail") + geom_hline(yintercept=1, linetype="dashed", color = "red")

#ml estimator
mle_Ex3_tail<-ggplot() + geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Example3_Exp_mles) +
  coord_cartesian(ylim = c(0.5, 1.5)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_mles_Ex3) + ylab("Estimated tail") + geom_hline(yintercept=1, linetype="dashed", color = "red")

#Hill estimator
hill_Ex3_tail<-ggplot() + geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_estimates_Example3_Exp_hill_times) +
  coord_cartesian(ylim = c(0.5, 10)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_hill_times_Ex3) + ylab("Estimated tail") + geom_hline(yintercept=1, linetype="dashed", color = "red")+ xlab("r")

grid.arrange(logMom_Ex1_tail,mle_Ex1_tail,hill_Ex1_tail,logMom_Ex2_tail,mle_Ex2_tail,hill_Ex2_tail,logMom_Ex3_tail,mle_Ex3_tail,hill_Ex3_tail,ncol=3)

```


```{r ScaleSimuplots, message=FALSE,echo=FALSE,fig.height=7,fig.align="center",fig.cap="\\label{Fig:ScaleSimu} Stability Plots for m=100 simulation runs for stable distributed waiting times with a tail parameter of 0.8 (top row), Pareto distributed waiting times with tail parameter 0.8 (middle row) and exponential distributed waiting times (lower row). Left column: log-moment estimator, right column: MLE. The grey thin lines are the stability plots for the different simulation runs and the dark lines are their means. The red dotted line shows the true tail parameter.", fig.show='hold', out.width = '90%'}
#Scale Parameter

#Example One
logMom_Ex1_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_logMoms_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex1) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex1_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_mles_Ex1) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex1) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Two

logMom_Ex2_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_logMoms_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex2) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red")

mle_Ex2_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_mles_Ex2) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex2) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red")

#Example Three

logMom_Ex3_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_logMoms_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",means.tbl_scales_logMoms_Ex3) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red") 

mle_Ex3_scale<-ggplot()+ geom_line(aes(x=k,y=value,group=rep),colour="lightgrey",data=tbl_scales_mles_Ex3) +
  coord_cartesian(ylim = c(0, 2)) +
  geom_line(aes(x=k, y=mw),colour="black",data=means.tbl_scales_mles_Ex3) + ylab("Estimated scale") + geom_hline(yintercept=1, linetype="dashed", color = "red")

grid.arrange(logMom_Ex1_scale,mle_Ex1_scale,logMom_Ex2_scale,mle_Ex2_scale,logMom_Ex3_scale,mle_Ex3_scale,ncol=2)
```

# Data example

We now want to apply the proposed method to a real data example, the solar flare data which was already mentioned in Section 1 and can be seen in Figure \ref{fig:thresholdedBursty}. The data were extracted from the "complete Hard X Ray Burst Spectrometer event list", a comprehensive reference for all measurements of the Hard X Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,772 events were detected, with the "vast  majority being solar flares". To assure stationarity and due to missing values during the years 1983 and 1984, we based our analysis just on the year 1982, in which 2,488 events happened. The list includes the start time, peak time, duration, and peak rate of each event. We have used "start time" as the variable for event times, and "peak rate" as the variable for event magnitudes. 
 
Before we apply the POT approach described in Section 5 to the solar flare data, we first have to check if all model assumptions are full-filled. The CTRE model is based on three main assumptions, which are repeated below. For each assumption, we suggest one means of checking if it holds: 

i.i.d.:

: After removing the "noise observations" below the smallest threshold 
  $\ell_0$, the pair sequence $(T(\ell_0, i), X(\ell_0,i))$ is i.i.d. 
  An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  

Uncoupled:

: Each $T(\ell, i)$ is independent of each $X(\ell, i)$. We propose an empirical copula
  plot to check for any dependence. 
  
  

${\rm ML}(\beta, \sigma)$ distribution of $T(\ell, i)$:

: Apply a cutoff at the lowest threshold $\ell_0$, 
  extract the threshold crossing times, 
  and create a QQ Plot for the Mittag-Leffler distribution. 
  Use a log-moment estimate of the tail parameter for the theoretical / population 
  quantiles of the plot.


Figures \ref{fig:flare-diagnostics-1}, \ref{fig:flare-diagnostics-2} and \ref{fig:flare-diagnostics-3} show the diagnostic plots for a minimum threshold chosen at the 200th order statistic. There is some residual autocorrelation for the sequence of threshold exceedance times that is not accounted for by the CTRE model.  

```{r flare-diagnostics-1, fig.height=7, fig.cap="\\label{fig:flare-diagnostics-1} Diagnostic plots for the solar flare data: auto-correlation function."}
flares_ctre <- flares %>% ctre() %>% thin(k = 150)
acf(flares_ctre)
```


```{r flare-diagnostics-2, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-2} Diagnostic plots for the solar flare data: empirical copula.",out.width="70%"}
empcopula(flares_ctre)
```

```{r flare-diagnostics-3, fig.height=4.5, fig.width=4.5, fig.align="center",fig.cap="\\label{fig:flare-diagnostics-3} Diagnostic plots for the solar flare data: QQ Plot.",out.width="70%"}
flares_ctre %>% interarrival() %>% mlqqplot(log = 'xy', tail = 0.85, main = "Mittag-Leffler QQ Plot")
```

Figure \ref{fig:flares} shows the stability plots for the solar flare data, on the left for the tail parameter and on the right for the scale parameter. Dotted lines show 95% confidence intervals, which are derived from the asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR], dashed lines show the deduced values of $\beta$ resp.\ $\sigma_0$. The stability plot for the tail stabilizes nicely round about 0.85 (dashed line), while it is a little bit harder to deduce an estimate for the scale parameter. Howerever, the stability plot for the scale parameter seems to stabilize round about $3 \times 10^7$ (dashed line).  

```{r solar-flare-tail-scale, message=FALSE, fig.height=4.5, fig.width=8, fig.cap="\\label{fig:flares} Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset. Dotted horizontal lines are at $\\beta = 0.85$ and $\\sigma_0 = 3 \\times 10^7$ seconds $\\approx 0.95$ years."}
thin_flares_ctre <- flares %>% ctre() %>% thin(k = 700)
par(mfrow=c(1,2))
MLestimates(thin_flares_ctre, tail = 0.9, scale = 3 * 1E7)
```

The fit with a Mittag-Leffler distribution ($\beta = 0.85$) is good (see Figure \ref{fig:flare-diagnostics-3}), though there are signs that the power-law tail tapers off for very large inter-threshold crossing times. There is no apparent dependence between threshold exceedance times and event magnitudes seen in the copula plot (see Figure \ref{fig:flare-diagnostics-2}). We also counduct a bootstrapped LRT for the null hypothesis of exponential distributed inter-arrival times and received a $p$-value of $p<0.01$. 

# Predicting the time of the next threshold crossing

According to Figure \ref{fig:flares}, for a threshold $\ell$ at the $k$-th order 
statistic, the fitted threshold exceedance time distribution is 
$$
T(\ell) \sim {\rm ML}(\beta, k^{-1/\beta} \sigma_0), 
$$
where $\beta = 0.85$ and $\sigma_0 = 3.0 \times 10^7 {\rm sec}$. 
Unlike the exponential distribution, the Mittag-Leffler distribution is not memoryless, and the probability density of the time $t$ until the next threshold crossing will depend on the time $t_0$ elapsed since the last threshold crossing.
This density equals 
$$
p(t|\beta, \sigma_0, \ell, t_0) = \frac{f(t + t_0 | \beta, k^{-1/\beta} \sigma_0)}{\mathbf P[T_\ell > t_0]}
$$
where $f(\,\cdot\, | \beta, k^{-1/\beta} \sigma_0)$ is the probability density of ${\rm ML}(\beta, k^{-1/\beta} \sigma_0)$. 
The more time has passed without a threshold crossing, the more the probability distribution shifts towards larger values for the next crossing
(see Figure \ref{fig:hazard}, left panel). The hazard rate 
$$
h(t) = \frac{f(t| \beta, k^{-1/\beta} \sigma_0))}{\int_t^\infty f(\tau| \beta, k^{-1/\beta} \sigma_0))\,d\tau}
$$
represents the risk of a threshold crossing per unit time, and is a decreasing function for the Mittag-Leffler distribution. 
```{r hazard, fig.height=4, fig.cap="\\label{fig:hazard} Left: Conditional distribution of time until next threshold crossing, depending on elapsed time $t_0$ since last crossing ($\\beta = 0.8$, $\\sigma_0 = 1$). Right: Hazard rate depending on tail parameter $\\beta$."}
tail <- 0.7
scale <- 1
t_0 <- c(0, 1, 10)
from <- 0.1
to <- 100 * scale
xx <- exp(seq(from = log(from), to = log(to), length.out = 100))
par(mfrow = c(1,2))
df1<-data.frame(x=xx,y=rep(1, length(xx)))
col<-c("red","blue","darkgreen","black")

plot(xx, rep(1, length(xx)), ylim = c(0.001,1), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'p')
for (k in 1:length(t_0)) {
  cond <- pml(q = t_0[k], tail = tail, scale = scale, lower.tail = FALSE)
  yy <- dml(x = xx + t_0[k], tail = tail, scale = scale) / cond
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("t_0 = 0", "t_0 = 1", "t_0 = 10"), col = c("red","blue","darkgreen"), lty = 2:4)

betas <- c(0.7, 0.8, 0.95, 0.99)
t_0 <- 1

plot(xx, rep(1, length(xx)), ylim = c(0.001,2), type = 'n', log = 'xy', 
     xlab = 't', ylab = 'h')
for (k in 1:length(betas)) {
  yy <- dml(x = xx, tail = betas[k], scale = scale) / pml(
    q = xx,
    tail = betas[k],
    scale = scale,
    lower.tail = FALSE
  )
  lines(xx,yy, col = col[k], lty = k+1)
}
legend("bottomleft", c("beta = 0.7", "beta = 0.8", "beta = 0.95", "beta = 0.99"), col = c("red","blue","darkgreen","black"), lty = 2:5)

```
The closer $\beta$ is to $1$, the more the hazard rate mimics that of an 
exponential distribution (a constant function, see Figure \ref{fig:hazard}, 
right panel). 


# Discussion & Conclusion

We have extended the POT (Peaks-over-Threshold) model, a mainstay of extreme value theory, to "bursty" time series, which have been studied 
intensively in statistical physics. Burstiness is characterized by power-law waiting times between events, and we have shown that the Mittag-Leffler distribution arises naturally as a scaling limit for the inter-exceedance times of high thresholds. Moreover, we have derived the following non-linear scaling behaviour: $\sigma \sim p^{-1/\beta}$, where $\sigma$ is the scale parameter of the distribution of threshold 
exceedance times, $p$ is the fraction of magnitudes above the threshold, and $\beta$ the exponent of the power law. 
This "anomalous" scaling behaviour in the bursty setting entails two phenomena: 

i) a heavy tail of the inter-arrival time distribution of threshold crossings (long rests), and 

ii) a high propensity for more threshold crossing events immediately after each threshold crossing event (bursts). 

The Mittag-Leffler distribution captures both phenomena, due to its heavy tail as well as its stretched exponential (peaked) asymptotics for small times. It generalizes the exponential distribution, and in the solar flare data example, this generalization is warranted, because the likelihood-ratio test is strongly significant. 

When we introduced the CTRE model, we assumed that all events are i.i.d. This assumption is likely sufficient but not necessary for our limit theorem to hold. Moreover, any data below a (minimum) threshold $\ell_0$ is discarded for CTREs, and hence need not satisfy the i.i.d. assumption.For the purposes of statistical inference, we merely require that the inter-threshold-crossing times are i.i.d. 

The bursty CTRE approach to model "non-Poissonian" threshold crossing times should be contrasted with the (now standard) approach of clusters of extremes, see e.g. @ferro2003inference. In this approach, i.i.d. event sequences of magnitudes are generalized to stationary sequences of
event magnitudes (subject to a mixing condition). The two approaches are fundamentally different: A clustering model assumes that each event 
belongs to one particular (latent) group of events. For bursts, however, the aim is to identify an underlying scale-free pattern in the event 
dynamics, which is often characteristic of complex systems. It is an interesting open problem to develop quality criteria, based
e.g. on measures of surprise [@Lee15], which guide an applied statistician in the choice between a clustering and a CTRE approach for a particular problem. Moreover, we believe it may be possible to unify the two approaches by considering CTREs based on MRPs with a _stationary_, rather than i.i.d., sequence of magnitudes. 

Finally, a purely scale-free pattern for event times may be too rigid as an 
assumption for some bursty time series, because often the heavy-tailed character of the inter-arrival time
distribution does not hold at all time scales; rather, it applies at short and intermediate time scales, and is truncated (or tempered, 
reverting to an exponential distribution) at very long time scales [see e.g. @MeerschaertRoyQin; and @Aban06]. In such situations, a "tempered" Mittag-Leffler distribution may provide a more realistic fit, which we aim to introduce in follow-up work. 

# Acknowledgements {-}

The authors would like to thank Prof. Peter Scheffler for insights on stochastic process limits for CTRMs, Prof. Roland Fried for discussion according the statistical methods and Gurtek Gill who helped create the MittagLeffleR R-package. 


\newpage

# References {-}

